{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from multiprocessing import shared_memory\n",
    "from multiprocessing.dummy import Pool\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import multiprocessing as mp\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import mp_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_factor = 3\n",
    "num_rf_predictors = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.read_csv('data/Ath_TF_list.txt', sep='\\t')\n",
    "tf_list = tf_df['Gene_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df = pd.read_csv('data/SS/92_DEG_Clusters.csv', index_col=0)\n",
    "deg_genes = deg_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg genes for presentation only:\n",
    "deg_genes = ['AT1G77760', 'AT3G44300', 'AT1G69870', 'AT2G46680', 'AT2G46820', 'AT1G14040']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('data/GSE111062_RAW/expression.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_genes = pd.Series(list(set(deg_genes).intersection(set(ts_df.index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('data/GSE111062_RAW/meta_data.tsv', sep='\\t')\n",
    "ts_exp_index = meta_df[meta_df['isTs']]\n",
    "# ts_exp_index_target =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].condName\n",
    "# ts_exp_index_source =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].prevCol\n",
    "ts_exp_index_target =  ts_exp_index.condName\n",
    "ts_exp_index_source =  ts_exp_index.condName\n",
    "regulator_gene_index = ts_df.index\n",
    "regulator_gene_index = pd.Series(list(set(tf_list).intersection(set(regulator_gene_index))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [04:41<00:00, 46.89s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr = RandomForestRegressor(random_state=0)\n",
    "\n",
    "\n",
    "ts_train_y_list = ts_df[ts_exp_index_target]\n",
    "\n",
    "result_list = []\n",
    "result_measure_list = []\n",
    "\n",
    "for target_gene in tqdm(target_genes):\n",
    "\n",
    "    train_gene_index = regulator_gene_index[regulator_gene_index != target_gene]\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[train_gene_index]\n",
    "\n",
    "    ts_train_y = ts_train_y_list.loc[target_gene]\n",
    "\n",
    "    input_mean = ts_train_X.mean()\n",
    "    input_std = ts_train_X.std()\n",
    "    perturbation_input = input_mean.copy()\n",
    "    perturbation_input = np.repeat(np.array(input_mean), repeats=len(input_mean), axis=0)\n",
    "    perturbation_input = perturbation_input.reshape(len(input_mean),len(input_mean)) + np.diagflat(np.array([ts_train_X.values.std()]*len(input_mean)) * perturbation_factor)\n",
    "\n",
    "    func = partial(mp_run.rf_feature_importance, ts_train_X, ts_train_y)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(func, range(num_rf_predictors))\n",
    "\n",
    "    base_predictions = [result.predict(np.array(input_mean).reshape(1,-1))[0] for result in results]\n",
    "    y_std = ts_train_y.std()\n",
    "\n",
    "    perturbation_input_list = np.array_split(perturbation_input, 10)\n",
    "    perturbation_input_shapes = [p.shape for p in perturbation_input_list]\n",
    "    shared_memory_list = []\n",
    "    for i, p in enumerate(perturbation_input_list):\n",
    "        shm = shared_memory.SharedMemory(create=True, size=p.nbytes, name=\"perturbation_input_\"+str(i))\n",
    "        buffer = np.ndarray(p.shape, dtype=p.dtype, buffer=shm.buf)\n",
    "        buffer[:] = p[:]\n",
    "        shared_memory_list.append(shm)\n",
    "\n",
    "\n",
    "    def f(perturbation_input_shapes, x):\n",
    "        pred_list = []\n",
    "        for i, shape in enumerate(perturbation_input_shapes):\n",
    "\n",
    "            # Attach to the existing shared memory\n",
    "            existing_shm = shared_memory.SharedMemory(name='perturbation_input_'+str(i))\n",
    "            # Read from the shared memory (we know the size is 1)\n",
    "            c = np.ndarray(shape, dtype=np.float64, buffer=existing_shm.buf)\n",
    "            pred_list.append(x.predict(c))\n",
    "            existing_shm.close()\n",
    "        return np.concatenate(pred_list)\n",
    "\n",
    "    func = partial(f, perturbation_input_shapes)\n",
    "\n",
    "    with mp.Pool(processes=20) as pool:\n",
    "        perturbation_predictions = pool.map(func, results)\n",
    "\n",
    "    for shm in shared_memory_list:\n",
    "        shm.close()\n",
    "        shm.unlink()\n",
    "\n",
    "\n",
    "    perturbation_measures = [(perturbation_prediction - base_prediction)/y_std for perturbation_prediction, base_prediction in zip(perturbation_predictions, base_predictions)]\n",
    "    importance_matrix = np.array(perturbation_measures).T\n",
    "    importance_df = pd.DataFrame(index=train_gene_index, data=importance_matrix, columns=range(num_rf_predictors))\n",
    "    importance_df_list\n",
    "    mean_importance = importance_df.mean(axis=1)\n",
    "    top_influence_genes = train_gene_index[np.argsort(mean_importance)[-5:]]\n",
    "    importance_df_list.append(mean_importance)\n",
    "    data_mean = ts_df.T[top_influence_genes].mean()\n",
    "    data_std = ts_df.T[top_influence_genes].std()\n",
    "    regr = RandomForestRegressor(random_state=42, warm_start=True, n_estimators=100, n_jobs=20)\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[top_influence_genes]\n",
    "    regr = regr.fit(ts_train_X, ts_train_y)\n",
    "\n",
    "    base_prediction = regr.predict(np.array(data_mean).reshape(1,-1))[0]\n",
    "    y_std = ts_df.T.std()[target_gene]\n",
    "    perturbation_list = list(powerset(top_influence_genes))[1:]\n",
    "\n",
    "    perturbation_result_list = []\n",
    "    perturbation_list_names = ['; '.join(perturbation_genes) for perturbation_genes in perturbation_list]\n",
    "    for perturbation_genes in perturbation_list:\n",
    "        perturbation_input = data_mean.copy()\n",
    "        for gene in perturbation_genes:\n",
    "            perturbation_input[gene] += data_std[gene] * perturbation_factor\n",
    "        perturbation_prediction = regr.predict(np.array(perturbation_input).reshape(1,-1))[0]\n",
    "        perturbation_measure = (perturbation_prediction - base_prediction)/y_std\n",
    "        perturbation_result_list.append(perturbation_measure)\n",
    "    result_list.append(np.array(perturbation_list_names)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "    result_measure_list.append(np.array(perturbation_result_list)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure_list = np.array(result_measure_list)\n",
    "result_list = np.array(result_list)\n",
    "out_df = pd.DataFrame()\n",
    "out_df.index = target_genes\n",
    "for i in range(5):\n",
    "    comb_name = 'top_{}_combination'.format(i+1)\n",
    "    score_name = 'top_{}_score'.format(i+1)\n",
    "    out_df[comb_name] = result_list[:,i]\n",
    "    out_df[score_name] = result_measure_list[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('output/GSE111062/presentation_comb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email import header\n",
    "\n",
    "\n",
    "for importance_series, target_gene in zip(importance_df_list, target_genes):\n",
    "    importance_series.to_csv('output/GSE111062/'+target_gene+'_rankings.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G49690')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G26744')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G23250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G26744')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0625736e76ce7a086b05dcdb3b30b057da1874f4b7d94f712ab6b40a66351ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
