{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from multiprocessing import shared_memory\n",
    "from multiprocessing.dummy import Pool\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import multiprocessing as mp\n",
    "from itertools import chain, combinations\n",
    "import sys\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import mp_run\n",
    "\n",
    "import concurrent.futures\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_factor = 3\n",
    "num_rf_predictors = 500\n",
    "\n",
    "target_tf = 'AT2G46680'\n",
    "\n",
    "induction_flag = -1\n",
    "mp_threads = 20\n",
    "# if (len(sys.argv)>=3):\n",
    "#     induction_flag = bool(sys.argv[1])\n",
    "#     mp_threads = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.read_csv('data/wrky_regulators.csv')\n",
    "tf_list = tf_df['Gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_2_3(iterable):\n",
    "    \"powerset([1,2,3]) -->  (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv('data/wrky_targets_neg.csv')\n",
    "if (induction_flag > 0):\n",
    "    target_df = pd.read_csv('data/wrky_targets_pos.csv')\n",
    "deg_genes = target_df['Gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('data/GSE97500/expression.tsv', sep='\\t', index_col=0)\n",
    "c = pd.Series(list(set(deg_genes).intersection(set(ts_df.index))))\n",
    "tf_list = pd.Series(list(set(tf_list).intersection(set(ts_df.index))))\n",
    "meta_df = pd.read_csv('data/GSE97500/meta_data.tsv', sep='\\t')\n",
    "ts_exp_index = meta_df[meta_df['isTs']]\n",
    "ts_exp_index_target =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].condName\n",
    "ts_exp_index_source =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].prevCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_genes = set(deg_genes).intersection(set(ts_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_trivial_targets = []\n",
    "for target in target_genes:\n",
    "    if ts_df.loc[target].mean() != 0.0:\n",
    "        non_trivial_targets.append(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_genes = pd.Series(non_trivial_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts_train_y_list = ts_df[ts_exp_index_target]\n",
    "\n",
    "result_list = []\n",
    "result_measure_list = []\n",
    "\n",
    "p_val_res_list = []\n",
    "\n",
    "for target_gene in tqdm(target_genes):\n",
    "    # train_gene_index = tf_list[tf_list != target_gene]\n",
    "    train_gene_index = tf_list\n",
    "    \n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[train_gene_index]\n",
    "\n",
    "    ts_train_y = ts_train_y_list.loc[target_gene]\n",
    "\n",
    "    input_mean = ts_train_X.mean()\n",
    "    input_std = ts_train_X.std()\n",
    "    # two set of perturbations:\n",
    "    # one with each WRKY and HB7 perturbed at the same time\n",
    "    # another, i.e., the alt one with just each WRKY perturbed\n",
    "    perturbation_input = input_mean.copy()\n",
    "    perturbation_input_alt = input_mean.copy()\n",
    "    perturbation_input[target_tf] += input_std[target_tf]*perturbation_factor\n",
    "    perturbation_input = np.tile(perturbation_input.values, (len(input_mean),1))\n",
    "    perturbation_input_alt = np.tile(perturbation_input_alt.values, (len(input_mean),1))\n",
    "    for i, tf_name in enumerate(tf_list):\n",
    "        if tf_name == target_tf: continue\n",
    "        perturbation_input[i][i] += input_std[tf_name]*perturbation_factor\n",
    "        perturbation_input_alt[i][i] += input_std[tf_name]*perturbation_factor\n",
    "    func = partial(mp_run.rf_feature_importance, ts_train_X, ts_train_y, perturbation_input, perturbation_input_alt)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(func, range(num_rf_predictors))\n",
    "    results = np.array(results)\n",
    "    target_tf_index = np.where(tf_list == target_tf)[0][0]\n",
    "    p_val_list = []\n",
    "    for i, tf_name in enumerate(tf_list):\n",
    "        if i == target_tf_index: \n",
    "            t_val, p_val = stats.ttest_rel(results[:, 0, target_tf_index], np.zeros(num_rf_predictors))\n",
    "        else:\n",
    "            t_val, p_val = stats.ttest_rel(results[:, 0, i], results[:, 0, target_tf_index] + results[:, 1, i])\n",
    "        if (induction_flag*t_val > 0): p_val_list.append(p_val)\n",
    "        else: p_val_list.append(1)\n",
    "    p_val_res_list.append(p_val_list)\n",
    "\n",
    "tf_df.index = tf_df['Gene']\n",
    "out_df = pd.DataFrame(index=target_genes, columns=tf_df.loc[tf_list]['Symbol'], data=np.array(p_val_res_list))\n",
    "\n",
    "out_df.to_csv('./output/xb_wrky_inf_pval_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.index = tf_df['Gene']\n",
    "out_df = pd.DataFrame(index=target_genes, columns=tf_df.loc[tf_list]['Symbol'], data=np.array(p_val_res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('./output/xb_wrky_inf_pval_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.index = tf_df['Gene']\n",
    "tf_df.loc[tf_list]['Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regr = RandomForestRegressor(random_state=0)\n",
    "\n",
    "ts_train_y_list = ts_df[ts_exp_index_target]\n",
    "\n",
    "result_list = []\n",
    "result_measure_list = []\n",
    "\n",
    "for target_gene in tqdm(target_genes):\n",
    "    train_gene_index = tf_list[tf_list != target_gene]\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[train_gene_index]\n",
    "\n",
    "    ts_train_y = ts_train_y_list.loc[target_gene]\n",
    "\n",
    "    input_mean = ts_train_X.mean()\n",
    "    input_std = ts_train_X.std()\n",
    "    perturbation_input = input_mean.copy()\n",
    "    perturbation_input = np.repeat(np.array(input_mean), repeats=len(input_mean), axis=0)\n",
    "    perturbation_input = perturbation_input.reshape(len(input_mean),len(input_mean)) + np.diagflat(np.array([ts_train_X.values.std()]*len(input_mean)) * perturbation_factor)\n",
    "\n",
    "    func = partial(mp_run.rf_feature_importance, ts_train_X, ts_train_y)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(func, range(num_rf_predictors))\n",
    "\n",
    "\n",
    "    base_predictions = [result.predict(np.array(input_mean).reshape(1,-1))[0] for result in results]\n",
    "    y_std = ts_train_y.std()\n",
    "\n",
    "    perturbation_input_list = np.array_split(perturbation_input, 10)\n",
    "    perturbation_input_shapes = [p.shape for p in perturbation_input_list]\n",
    "    shared_memory_list = []\n",
    "    for i, p in enumerate(perturbation_input_list):\n",
    "        shm = shared_memory.SharedMemory(create=True, size=p.nbytes, name=\"perturbation_input_\"+str(i))\n",
    "        buffer = np.ndarray(p.shape, dtype=p.dtype, buffer=shm.buf)\n",
    "        buffer[:] = p[:]\n",
    "        shared_memory_list.append(shm)\n",
    "\n",
    "\n",
    "    def f(perturbation_input_shapes, x):\n",
    "        pred_list = []\n",
    "        for i, shape in enumerate(perturbation_input_shapes):\n",
    "\n",
    "            # Attach to the existing shared memory\n",
    "            existing_shm = shared_memory.SharedMemory(name='perturbation_input_'+str(i))\n",
    "            # Read from the shared memory (we know the size is 1)\n",
    "            c = np.ndarray(shape, dtype=np.float64, buffer=existing_shm.buf)\n",
    "            pred_list.append(x.predict(c))\n",
    "            existing_shm.close()\n",
    "        return np.concatenate(pred_list)\n",
    "\n",
    "    func = partial(f, perturbation_input_shapes)\n",
    "\n",
    "    with mp.Pool(processes=mp_threads) as pool:\n",
    "        perturbation_predictions = pool.map(func, results)\n",
    "\n",
    "    for shm in shared_memory_list:\n",
    "        shm.close()\n",
    "        shm.unlink()\n",
    "\n",
    "\n",
    "    perturbation_measures = [(perturbation_prediction - base_prediction)/y_std for perturbation_prediction, base_prediction in zip(perturbation_predictions, base_predictions)]\n",
    "    importance_matrix = np.array(perturbation_measures).T\n",
    "    importance_df = pd.DataFrame(index=train_gene_index, data=importance_matrix, columns=range(num_rf_predictors))\n",
    "    importance_df_list = []\n",
    "    mean_importance = importance_df.mean(axis=1)\n",
    "    if (induction_flag):\n",
    "        top_influence_genes = train_gene_index[np.argsort(mean_importance)[::-1][:5]]\n",
    "    else:\n",
    "        top_influence_genes = train_gene_index[np.argsort(mean_importance)[:5]]\n",
    "    importance_df_list.append(mean_importance)\n",
    "    data_mean = ts_df.T[top_influence_genes].mean()\n",
    "    data_std = ts_df.T[top_influence_genes].std()\n",
    "    regr = RandomForestRegressor(random_state=42, warm_start=True, n_estimators=100, n_jobs=20)\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[top_influence_genes]\n",
    "    regr = regr.fit(ts_train_X, ts_train_y)\n",
    "\n",
    "    base_prediction = regr.predict(np.array(data_mean).reshape(1,-1))[0]\n",
    "    y_std = ts_df.T.std()[target_gene]\n",
    "    perturbation_list = list(choose_2_3(top_influence_genes))\n",
    "\n",
    "    perturbation_result_list = []\n",
    "    perturbation_list_names = ['; '.join(perturbation_genes) for perturbation_genes in perturbation_list]\n",
    "    for perturbation_genes in perturbation_list:\n",
    "        perturbation_input = data_mean.copy()\n",
    "        for gene in perturbation_genes:\n",
    "            perturbation_input[gene] += data_std[gene] * perturbation_factor\n",
    "        perturbation_prediction = regr.predict(np.array(perturbation_input).reshape(1,-1))[0]\n",
    "        perturbation_measure = (perturbation_prediction - base_prediction)/y_std\n",
    "        perturbation_result_list.append(perturbation_measure)\n",
    "    if (induction_flag):\n",
    "        result_list.append(np.array(perturbation_list_names)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "        result_measure_list.append(np.array(perturbation_result_list)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "    else:\n",
    "        result_list.append(np.array(perturbation_list_names)[np.argsort(perturbation_result_list)[:5]])\n",
    "        result_measure_list.append(np.array(perturbation_result_list)[np.argsort(perturbation_result_list)[:5]])\n",
    "        \n",
    "    del importance_df_list\n",
    "    del importance_df\n",
    "    del shared_memory_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shm in shared_memory_list:\n",
    "        shm.close()\n",
    "        shm.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure_list = np.array(result_measure_list)\n",
    "result_list = np.array(result_list)\n",
    "out_df = pd.DataFrame()\n",
    "out_df.index = target_genes[:50]\n",
    "for i in range(5):\n",
    "    comb_name = 'top_{}_combination'.format(i+1)\n",
    "    score_name = 'top_{}_score'.format(i+1)\n",
    "    out_df[comb_name] = result_list[:,i]\n",
    "    out_df[score_name] = result_measure_list[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (induction_flag):\n",
    "    out_df.to_csv('output/wrky_presentation_comb_pos.csv')\n",
    "else:\n",
    "    out_df.to_csv('output/wrky_presentation_comb_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('./output/rf_wrky_inf_pval_neg.csv', index_col=0)\n",
    "# res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc_res_df = pd.read_csv('./output/neg_res_new.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df.index = tf_df['Gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc_res_df.index = tf_df.loc[pymc_res_df.index]['Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc_res_df = pymc_res_df.loc[res_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc_res_df = pymc_res_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_index = pd.Index(set(res_df.index).intersection(set(pymc_res_df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymc_res_df = pymc_res_df.loc[common_index]\n",
    "pymc_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1-pymc_res_df).to_csv('./output/sample_pymc_res_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.loc[common_index].to_csv('./output/sample_rf_res_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = (pd.concat([1-pymc_res_df,res_df.loc[common_index]])\n",
    "   .stack()\n",
    "   .groupby(level=[0,1])\n",
    "   .apply(tuple)\n",
    "   .unstack()\n",
    " ).loc[common_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df.to_csv('./output/sample_comb_res_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_out_df = pd.read_csv('./output/rf_wrky_inf_pval_neg.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_df = (pd.concat([out_df,rf_out_df.loc[out_df.index]])\n",
    "   .stack()\n",
    "   .groupby(level=[0,1])\n",
    "   .apply(tuple)\n",
    "   .unstack()\n",
    ")\n",
    "comb_df.to_csv('./output/sample_xb_rf_comb_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_pval_df = pd.read_csv('./output/xb_wrky_inf_pval_neg.csv', index_col=0)\n",
    "xbrf_pval_df = pd.read_csv('./output/xbrf_wrky_inf_pval_neg.csv', index_col=0)\n",
    "rf_pval_df = pd.read_csv('./output/rf_wrky_inf_pval_neg.csv', index_col=0)\n",
    "ab_pval_df = pd.read_csv('./output/ab_wrky_inf_pval_neg.csv', index_col=0)\n",
    "target_index = xb_pval_df.index\n",
    "wrky_names = xb_pval_df.columns\n",
    "\n",
    "xbrf_pval_df=xbrf_pval_df.loc[target_index, wrky_names]\n",
    "rf_pval_df=rf_pval_df.loc[target_index, wrky_names]\n",
    "ab_pval_df=ab_pval_df.loc[target_index, wrky_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbrf_pval_df < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.logical_and(xbrf_pval_df < 0.05, rf_pval_df < 0.05)\n",
    "b = np.logical_and(xb_pval_df < 0.05, ab_pval_df < 0.05)\n",
    "np.logical_and(a,b)['WRKY31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sss(x):\n",
    "    return (x*2, x*x)\n",
    "\n",
    "a, b = sss(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('inf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45e8b4e597901076a3793f077aa4917c88e4588bf4d8f42473ef14bed5440d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
