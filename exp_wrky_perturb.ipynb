{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from multiprocessing import shared_memory\n",
    "from multiprocessing.dummy import Pool\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import multiprocessing as mp\n",
    "from itertools import chain, combinations\n",
    "import sys\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import mp_run\n",
    "\n",
    "import concurrent.futures\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_factor = 3\n",
    "num_rf_predictors = 500\n",
    "\n",
    "target_tf = 'AT2G46680'\n",
    "\n",
    "induction_flag = 0\n",
    "mp_threads = 20\n",
    "# if (len(sys.argv)>=3):\n",
    "#     induction_flag = bool(sys.argv[1])\n",
    "#     mp_threads = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.read_csv('data/wrky_regulators.csv')\n",
    "tf_list = tf_df['Gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_2_3(iterable):\n",
    "    \"powerset([1,2,3]) -->  (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.read_csv('data/wrky_targets_neg.csv')\n",
    "if (induction_flag):\n",
    "    target_df = pd.read_csv('data/wrky_targets_pos.csv')\n",
    "deg_genes = target_df['Gene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('data/GSE97500/expression.tsv', sep='\\t', index_col=0)\n",
    "c = pd.Series(list(set(deg_genes).intersection(set(ts_df.index))))\n",
    "tf_list = pd.Series(list(set(tf_list).intersection(set(ts_df.index))))\n",
    "meta_df = pd.read_csv('data/GSE97500/meta_data.tsv', sep='\\t')\n",
    "ts_exp_index = meta_df[meta_df['isTs']]\n",
    "ts_exp_index_target =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].condName\n",
    "ts_exp_index_source =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].prevCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_genes = set(deg_genes).intersection(set(ts_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_trivial_targets = []\n",
    "for target in target_genes:\n",
    "    if ts_df.loc[target].mean() != 0.0:\n",
    "        non_trivial_targets.append(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_genes = pd.Series(non_trivial_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/639 [00:18<3:15:18, 18.37s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "ts_train_y_list = ts_df[ts_exp_index_target]\n",
    "\n",
    "result_list = []\n",
    "result_measure_list = []\n",
    "\n",
    "p_val_res_list = []\n",
    "\n",
    "for target_gene in tqdm(target_genes):\n",
    "    train_gene_index = tf_list[tf_list != target_gene]\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[train_gene_index]\n",
    "\n",
    "    ts_train_y = ts_train_y_list.loc[target_gene]\n",
    "\n",
    "    input_mean = ts_train_X.mean()\n",
    "    input_std = ts_train_X.std()\n",
    "    perturbation_input = input_mean.copy()\n",
    "    perturbation_input[target_tf] += input_std[target_tf]*perturbation_factor\n",
    "    perturbation_input = np.tile(perturbation_input.values, (len(input_mean),1))\n",
    "    for i, tf_name in enumerate(tf_list):\n",
    "        if tf_name == target_tf: continue\n",
    "        perturbation_input[i][i] += input_std[tf_name]*perturbation_factor\n",
    "\n",
    "    func = partial(mp_run.rf_feature_importance, ts_train_X, ts_train_y, perturbation_input)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(func, range(num_rf_predictors))\n",
    "    results = np.array(results)\n",
    "    target_tf_index = np.where(tf_list == target_tf)[0][0]\n",
    "    p_val_list = []\n",
    "    for i, tf_name in enumerate(tf_list):\n",
    "        if i == target_tf_index: \n",
    "            t_val, p_val = stats.ttest_rel(results[:, target_tf_index], np.zeros(num_rf_predictors))\n",
    "        else:\n",
    "            t_val, p_val = stats.ttest_rel(results[:,i], results[:, target_tf_index])\n",
    "        if (induction_flag*t_val > 0): p_val_list.append(p_val)\n",
    "        else: p_val_list.append(1)\n",
    "    p_val_res_list.append(p_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)\n",
    "target_tf_index = np.where(tf_list == target_tf)[0][0]\n",
    "p_val_list = []\n",
    "for i, tf_name in enumerate(tf_list):\n",
    "    if i == target_tf_index: \n",
    "        t_val, p_val = stats.ttest_rel(results[:, target_tf_index], np.zeros(num_rf_predictors))\n",
    "    else:\n",
    "        t_val, p_val = stats.ttest_rel(results[:,i], results[:, target_tf_index])\n",
    "    if (induction_flag*t_val > 0): p_val_list.append(p_val)\n",
    "    else: p_val_list.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results)[:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=0.0, pvalue=1.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "stats.ttest_rel([1,2,3], [3,2,1])\n",
    "# pairedtest([0,0,0], [0,0,0], 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/775 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr = RandomForestRegressor(random_state=0)\n",
    "\n",
    "ts_train_y_list = ts_df[ts_exp_index_target]\n",
    "\n",
    "result_list = []\n",
    "result_measure_list = []\n",
    "\n",
    "for target_gene in tqdm(target_genes):\n",
    "    train_gene_index = tf_list[tf_list != target_gene]\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[train_gene_index]\n",
    "\n",
    "    ts_train_y = ts_train_y_list.loc[target_gene]\n",
    "\n",
    "    input_mean = ts_train_X.mean()\n",
    "    input_std = ts_train_X.std()\n",
    "    perturbation_input = input_mean.copy()\n",
    "    perturbation_input = np.repeat(np.array(input_mean), repeats=len(input_mean), axis=0)\n",
    "    perturbation_input = perturbation_input.reshape(len(input_mean),len(input_mean)) + np.diagflat(np.array([ts_train_X.values.std()]*len(input_mean)) * perturbation_factor)\n",
    "\n",
    "    func = partial(mp_run.rf_feature_importance, ts_train_X, ts_train_y)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(func, range(num_rf_predictors))\n",
    "\n",
    "\n",
    "    base_predictions = [result.predict(np.array(input_mean).reshape(1,-1))[0] for result in results]\n",
    "    y_std = ts_train_y.std()\n",
    "\n",
    "    perturbation_input_list = np.array_split(perturbation_input, 10)\n",
    "    perturbation_input_shapes = [p.shape for p in perturbation_input_list]\n",
    "    shared_memory_list = []\n",
    "    for i, p in enumerate(perturbation_input_list):\n",
    "        shm = shared_memory.SharedMemory(create=True, size=p.nbytes, name=\"perturbation_input_\"+str(i))\n",
    "        buffer = np.ndarray(p.shape, dtype=p.dtype, buffer=shm.buf)\n",
    "        buffer[:] = p[:]\n",
    "        shared_memory_list.append(shm)\n",
    "\n",
    "\n",
    "    def f(perturbation_input_shapes, x):\n",
    "        pred_list = []\n",
    "        for i, shape in enumerate(perturbation_input_shapes):\n",
    "\n",
    "            # Attach to the existing shared memory\n",
    "            existing_shm = shared_memory.SharedMemory(name='perturbation_input_'+str(i))\n",
    "            # Read from the shared memory (we know the size is 1)\n",
    "            c = np.ndarray(shape, dtype=np.float64, buffer=existing_shm.buf)\n",
    "            pred_list.append(x.predict(c))\n",
    "            existing_shm.close()\n",
    "        return np.concatenate(pred_list)\n",
    "\n",
    "    func = partial(f, perturbation_input_shapes)\n",
    "\n",
    "    with mp.Pool(processes=mp_threads) as pool:\n",
    "        perturbation_predictions = pool.map(func, results)\n",
    "\n",
    "    for shm in shared_memory_list:\n",
    "        shm.close()\n",
    "        shm.unlink()\n",
    "\n",
    "\n",
    "    perturbation_measures = [(perturbation_prediction - base_prediction)/y_std for perturbation_prediction, base_prediction in zip(perturbation_predictions, base_predictions)]\n",
    "    importance_matrix = np.array(perturbation_measures).T\n",
    "    importance_df = pd.DataFrame(index=train_gene_index, data=importance_matrix, columns=range(num_rf_predictors))\n",
    "    importance_df_list = []\n",
    "    mean_importance = importance_df.mean(axis=1)\n",
    "    if (induction_flag):\n",
    "        top_influence_genes = train_gene_index[np.argsort(mean_importance)[::-1][:5]]\n",
    "    else:\n",
    "        top_influence_genes = train_gene_index[np.argsort(mean_importance)[:5]]\n",
    "    importance_df_list.append(mean_importance)\n",
    "    data_mean = ts_df.T[top_influence_genes].mean()\n",
    "    data_std = ts_df.T[top_influence_genes].std()\n",
    "    regr = RandomForestRegressor(random_state=42, warm_start=True, n_estimators=100, n_jobs=20)\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[top_influence_genes]\n",
    "    regr = regr.fit(ts_train_X, ts_train_y)\n",
    "\n",
    "    base_prediction = regr.predict(np.array(data_mean).reshape(1,-1))[0]\n",
    "    y_std = ts_df.T.std()[target_gene]\n",
    "    perturbation_list = list(choose_2_3(top_influence_genes))\n",
    "\n",
    "    perturbation_result_list = []\n",
    "    perturbation_list_names = ['; '.join(perturbation_genes) for perturbation_genes in perturbation_list]\n",
    "    for perturbation_genes in perturbation_list:\n",
    "        perturbation_input = data_mean.copy()\n",
    "        for gene in perturbation_genes:\n",
    "            perturbation_input[gene] += data_std[gene] * perturbation_factor\n",
    "        perturbation_prediction = regr.predict(np.array(perturbation_input).reshape(1,-1))[0]\n",
    "        perturbation_measure = (perturbation_prediction - base_prediction)/y_std\n",
    "        perturbation_result_list.append(perturbation_measure)\n",
    "    if (induction_flag):\n",
    "        result_list.append(np.array(perturbation_list_names)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "        result_measure_list.append(np.array(perturbation_result_list)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "    else:\n",
    "        result_list.append(np.array(perturbation_list_names)[np.argsort(perturbation_result_list)[:5]])\n",
    "        result_measure_list.append(np.array(perturbation_result_list)[np.argsort(perturbation_result_list)[:5]])\n",
    "        \n",
    "    del importance_df_list\n",
    "    del importance_df\n",
    "    del shared_memory_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor(random_state=1, warm_start=True, n_estimators=300, n_jobs=1)\n",
    "regr = regr.fit(ts_train_X, ts_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_mean['AT2G44745'] -= 3\n",
    "perturbation_input = input_mean.copy()\n",
    "perturbation_input[target_tf] += input_std[target_tf]*perturbation_factor\n",
    "perturbation_input = np.tile(perturbation_input.values, (len(input_mean),1))\n",
    "for i, tf_name in enumerate(tf_list):\n",
    "    if tf_name == target_tf: continue\n",
    "    perturbation_input[i][i] += input_std[tf_name]*perturbation_factor\n",
    "regr.predict(perturbation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.66666667e-02,  5.23333333e-01, -3.15333333e+00, -1.17876667e+02,\n",
       "        4.83333333e-01, -2.66666667e-01, -2.72400000e+01, -3.23333333e-01,\n",
       "       -7.56666667e-01,  1.31666667e+00, -6.72666667e+00,  3.13333333e-01,\n",
       "       -2.01666667e+00, -1.04000000e+00,  2.93666667e+00, -1.62310000e+02,\n",
       "        6.66666667e-02, -9.13333333e-01,  7.66666667e-02, -2.53100000e+01,\n",
       "       -2.43333333e-01,  1.02000000e+00,  3.97166667e+01, -3.40000000e-01,\n",
       "       -2.99000000e+00,  2.43000000e+00, -2.13333333e-01, -3.02000000e+00,\n",
       "       -5.43666667e+00, -1.56666667e-01, -1.38333333e+00, -2.11000000e+00,\n",
       "       -2.34333333e+00, -2.42333333e+00,  3.10666667e+00, -7.10666667e+00,\n",
       "        2.26000000e+00, -1.67333333e+00, -3.93333333e-01, -4.00666667e+00,\n",
       "       -1.66333333e+00, -1.56333333e+00,  1.14000000e+00, -7.50000000e-01,\n",
       "       -3.16666667e-01,  6.33333333e-01, -7.60000000e-01, -3.36666667e-01,\n",
       "       -1.14333333e+00,  7.70000000e-01, -6.03333333e-01, -1.62666667e+00,\n",
       "       -1.84333333e+00,  2.30000000e+00,  6.33333333e-02,  9.43333333e-01,\n",
       "       -1.83333333e-01,  2.66666667e-02, -9.13333333e-01,  1.16666667e-01,\n",
       "       -2.04100000e+01,  1.15200000e+01, -4.85853333e+02, -3.00000000e-02,\n",
       "        1.50000000e-01, -8.63933333e+01, -3.33333333e-02,  5.06666667e-01,\n",
       "        2.00000000e-02, -3.31866667e+01,  7.33333333e-02, -1.73000000e+00])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.predict(np.array(input_mean).reshape(1,-1))[0] - regr.predict(perturbation_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "775"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.65292437e+03, 3.89583333e+00, 3.89583333e+00, ...,\n",
       "        3.89583333e+00, 3.89583333e+00, 3.89583333e+00],\n",
       "       [1.79000000e+03, 6.43902853e+03, 1.79000000e+03, ...,\n",
       "        1.79000000e+03, 1.79000000e+03, 1.79000000e+03],\n",
       "       [1.54255208e+03, 1.54255208e+03, 6.19158062e+03, ...,\n",
       "        1.54255208e+03, 1.54255208e+03, 1.54255208e+03],\n",
       "       ...,\n",
       "       [2.52770833e+02, 2.52770833e+02, 2.52770833e+02, ...,\n",
       "        4.90179937e+03, 2.52770833e+02, 2.52770833e+02],\n",
       "       [1.15208333e+02, 1.15208333e+02, 1.15208333e+02, ...,\n",
       "        1.15208333e+02, 4.76423687e+03, 1.15208333e+02],\n",
       "       [8.44125000e+02, 8.44125000e+02, 8.44125000e+02, ...,\n",
       "        8.44125000e+02, 8.44125000e+02, 5.49315353e+03]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbation_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shm in shared_memory_list:\n",
    "        shm.close()\n",
    "        shm.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure_list = np.array(result_measure_list)\n",
    "result_list = np.array(result_list)\n",
    "out_df = pd.DataFrame()\n",
    "out_df.index = target_genes[:50]\n",
    "for i in range(5):\n",
    "    comb_name = 'top_{}_combination'.format(i+1)\n",
    "    score_name = 'top_{}_score'.format(i+1)\n",
    "    out_df[comb_name] = result_list[:,i]\n",
    "    out_df[score_name] = result_measure_list[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (induction_flag):\n",
    "    out_df.to_csv('output/wrky_presentation_comb_pos.csv')\n",
    "else:\n",
    "    out_df.to_csv('output/wrky_presentation_comb_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('inf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45e8b4e597901076a3793f077aa4917c88e4588bf4d8f42473ef14bed5440d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
