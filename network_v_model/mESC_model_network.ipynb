{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "from functools import cmp_to_key, partial\n",
    "import re\n",
    "\n",
    "import mp_run\n",
    "import conf_interval\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_course_compare(item1, item2, valued_time=False):\n",
    "    rep1, course1 = item1.split('@')\n",
    "    rep1 = rep1+course1[-1]\n",
    "    course1 = course1[:-1]\n",
    "    rep2, course2 = item2.split('@')\n",
    "    rep2 = rep2+course2[-1]\n",
    "    course2 = course2[:-1]\n",
    "    if (valued_time):\n",
    "        course1 = float(re.search(number_pattern, course1).group(1))\n",
    "        course2 = float(re.search(number_pattern, course2).group(1))\n",
    "    if rep1 < rep2:\n",
    "        return -1\n",
    "    elif rep1 > rep2:\n",
    "        return 1\n",
    "    else:\n",
    "        if course1 < course2:\n",
    "            return -1\n",
    "        elif course1 > course2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = pd.read_csv('../data/mESC/ExpressionData.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "\n",
    "formated_names = []\n",
    "for name in exp_df.columns:\n",
    "    name_splits = name.split('_')\n",
    "    rep_set.add(name_splits[3])\n",
    "    time_set.add(name_splits[2])\n",
    "    formated_names.append(name_splits[3]+'@'+name_splits[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df.columns = formated_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_rep_course = sorted(formated_names, key=cmp_to_key(time_course_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = exp_df[sorted_rep_course]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "for name in exp_df.columns:\n",
    "    name_splits = name.split('@')\n",
    "    rep_set.add(name_splits[0])\n",
    "    time_set.add(name_splits[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_list = []\n",
    "train_target_list = []\n",
    "test_source_list = []\n",
    "test_target_list = []\n",
    "for rep in rep_set:\n",
    "    matching = [s for s in sorted_rep_course if rep in s]\n",
    "    if len(matching) > 2:\n",
    "        train_source_list.extend(matching[0:-2])\n",
    "        train_target_list.extend(matching[1:-1])\n",
    "        test_source_list.append(matching[-2])\n",
    "        test_target_list.append(matching[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.read_csv('../data/mESC/SubNetwork.csv')\n",
    "regulator_set = set(network_df['Gene1'])\n",
    "target_set = set(network_df['Gene2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulator_set = regulator_set.intersection(set(exp_df.index))\n",
    "target_set = target_set.intersection(set(exp_df.index))\n",
    "all_gene_set = regulator_set.union(target_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dict = {target: [] for target in target_set}\n",
    "for ind, row in network_df.iterrows():\n",
    "    if (row['Gene1'] in regulator_set) and (row['Gene2'] in target_set):\n",
    "        network_dict[row['Gene2']].append(row['Gene1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = []\n",
    "value_list = []\n",
    "regulator_set = set()\n",
    "target_set = set()\n",
    "for key in network_dict.keys():\n",
    "    if (len(network_dict[key]) > 0):\n",
    "        key_list.append(key)\n",
    "        target_set.add(key)\n",
    "        value_list.append(\"; \".join(network_dict[key]))\n",
    "        for regulator in network_dict[key]:\n",
    "            regulator_set.add(regulator)\n",
    "all_gene_set = regulator_set.union(target_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.DataFrame(index=key_list)\n",
    "network_df['tf_list'] = value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_df = exp_df.apply(stats.zscore, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = exp_df[train_source_list]\n",
    "train_target = exp_df[train_target_list]\n",
    "test_source = exp_df[test_source_list]\n",
    "test_target = exp_df[test_target_list]\n",
    "\n",
    "target_df = pd.concat([train_target, test_target], axis=1)\n",
    "source_df = pd.concat([train_source, test_source], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in list(target_set):\n",
    "    if len(network_df.loc[a]['tf_list'].split('; ')) < 1 or network_df.loc[a]['tf_list'] == a:\n",
    "        target_set.remove(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gene_list = list(target_set)\n",
    "target_exp = target_df\n",
    "X = source_df.loc[list(regulator_set)]\n",
    "tf_list = list(regulator_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_calc = mp_run.MpCalc(target_gene_list, target_exp, X, network_df, train_source.loc[tf_list], train_target, test_source.loc[tf_list], test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 300/300 [00:14<00:00, 20.47it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.full_comp, range(iter_length)), total=iter_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(r)\n",
    "out_df = pd.DataFrame(index=target_gene_list)\n",
    "out_df['rf_score'] = r[:, 0]\n",
    "out_df['linear_score'] = r[:, 1]\n",
    "out_df['gs_rf_score'] = r[:, 2]\n",
    "out_df['gs_linear_score'] = r[:, 3]\n",
    "out_df['rf_with_linear_top_features_score'] = r[:, 4]\n",
    "out_df['linear_with_rf_top_features_score'] = r[:, 5]\n",
    "out_df['rf_rmse'] = r[:, 6]\n",
    "out_df['linear_rmse'] = r[:, 7]\n",
    "out_df['gs_rf_rmse'] = r[:, 8]\n",
    "out_df['gs_linear_rmse'] = r[:, 9]\n",
    "out_df['rf_with_linear_top_features_rmse'] = r[:, 10]\n",
    "out_df['linear_with_rf_top_features_rmse'] = r[:, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.922, -0.735)\n",
      "(-1.960, -1.383)\n",
      "(-1.692, -1.282)\n",
      "(-2.209, -1.519)\n",
      "(-1.171, -0.950)\n",
      "(-1.130, -0.862)\n"
     ]
    }
   ],
   "source": [
    "rf_conf_interval = conf_interval.conf_interval_calc(list(out_df['rf_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_conf_interval[2:] ])+')')\n",
    "linear_conf_interval = conf_interval.conf_interval_calc(list(out_df['linear_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_conf_interval[2:] ])+')')\n",
    "gs_rf_conf_interval = conf_interval.conf_interval_calc(list(out_df['gs_rf_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_rf_conf_interval[2:] ])+')')\n",
    "gs_linear_conf_interval = conf_interval.conf_interval_calc(list(out_df['gs_linear_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_linear_conf_interval[2:] ])+')')\n",
    "rf_with_linear_top_features_conf_interval = conf_interval.conf_interval_calc(list(out_df['rf_with_linear_top_features_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_with_linear_top_features_conf_interval[2:] ])+')')\n",
    "linear_with_rf_top_features_conf_interval = conf_interval.conf_interval_calc(list(out_df['linear_with_rf_top_features_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_with_rf_top_features_conf_interval[2:] ])+')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.442, 0.492)\n",
      "(0.486, 0.535)\n",
      "(0.493, 0.548)\n",
      "(0.496, 0.549)\n",
      "(0.467, 0.518)\n",
      "(0.450, 0.500)\n"
     ]
    }
   ],
   "source": [
    "rf_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['rf_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_conf_interval_rmse[2:] ])+')')\n",
    "linear_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['linear_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_conf_interval_rmse[2:] ])+')')\n",
    "gs_rf_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['gs_rf_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_rf_conf_interval_rmse[2:] ])+')')\n",
    "gs_linear_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['gs_linear_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_linear_conf_interval_rmse[2:] ])+')')\n",
    "rf_with_linear_top_features_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['rf_with_linear_top_features_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_with_linear_top_features_conf_interval_rmse[2:] ])+')')\n",
    "linear_with_rf_top_features_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['linear_with_rf_top_features_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_with_rf_top_features_conf_interval_rmse[2:] ])+')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf_score                            -0.822921\n",
       "linear_score                        -1.630093\n",
       "gs_rf_score                         -1.469246\n",
       "gs_linear_score                     -1.815687\n",
       "rf_with_linear_top_features_score   -1.056953\n",
       "linear_with_rf_top_features_score   -0.986664\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.mean()[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf_rmse                             0.466460\n",
       "linear_rmse                         0.510472\n",
       "gs_rf_rmse                          0.520083\n",
       "gs_linear_rmse                      0.522475\n",
       "rf_with_linear_top_features_rmse    0.491276\n",
       "linear_with_rf_top_features_rmse    0.473984\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.mean()[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "model_combs = list(combinations(out_df.columns[:6], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_score has statisically better performance than linear_score, with p-val of 2.0174658909807522e-07\n",
      "confidence interval: (0.593, 1.099)\n",
      "rf_score has statisically better performance than gs_rf_score, with p-val of 9.153268740522008e-11\n",
      "confidence interval: (0.508, 0.822)\n",
      "rf_score has statisically better performance than gs_linear_score, with p-val of 1.457397541011229e-07\n",
      "confidence interval: (0.736, 1.337)\n",
      "rf_score has statisically better performance than rf_with_linear_top_features_score, with p-val of 1.265123865281187e-13\n",
      "confidence interval: (0.187, 0.286)\n",
      "rf_score has statisically better performance than linear_with_rf_top_features_score, with p-val of 0.0025694463934270917\n",
      "confidence interval: (0.088, 0.264)\n",
      "linear_score and gs_rf_score don't have statistically different performance\n",
      "linear_score and gs_linear_score don't have statistically different performance\n",
      "rf_with_linear_top_features_score has statisically better performance than linear_score, with p-val of 0.00023581153675353262\n",
      "confidence interval: (-0.869, -0.354)\n",
      "linear_with_rf_top_features_score has statisically better performance than linear_score, with p-val of 2.5807066503118592e-06\n",
      "confidence interval: (-0.910, -0.455)\n",
      "gs_rf_score has statisically better performance than gs_linear_score, with p-val of 0.029875649336262442\n",
      "confidence interval: (0.131, 0.677)\n",
      "rf_with_linear_top_features_score has statisically better performance than gs_rf_score, with p-val of 1.83945227830867e-05\n",
      "confidence interval: (-0.579, -0.270)\n",
      "linear_with_rf_top_features_score has statisically better performance than gs_rf_score, with p-val of 7.326871576484736e-06\n",
      "confidence interval: (-0.667, -0.318)\n",
      "rf_with_linear_top_features_score has statisically better performance than gs_linear_score, with p-val of 5.412135678818199e-05\n",
      "confidence interval: (-1.121, -0.501)\n",
      "linear_with_rf_top_features_score has statisically better performance than gs_linear_score, with p-val of 3.023090000761396e-06\n",
      "confidence interval: (-1.178, -0.589)\n",
      "rf_with_linear_top_features_score and linear_with_rf_top_features_score don't have statistically different performance\n"
     ]
    }
   ],
   "source": [
    "for a, b in model_combs:\n",
    "    t, p = stats.ttest_rel(out_df[a], out_df[b])\n",
    "    c, d, lower, upper = conf_interval.conf_interval_calc(list(out_df[a]-out_df[b]))\n",
    "    if (p > 0.05):\n",
    "        print('{} and {} don\\'t have statistically different performance'.format(a, b))\n",
    "        continue\n",
    "    if (t > 0):\n",
    "        print('{} has statisically better performance than {}, with p-val of {}'.format(a, b, p))\n",
    "        print('confidence interval: ({:.3f}, {:.3f})'.format(lower, upper))\n",
    "    else:\n",
    "        print('{} has statisically better performance than {}, with p-val of {}'.format(b, a, p))\n",
    "        print('confidence interval: ({:.3f}, {:.3f})'.format(lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 300/300 [00:09<00:00, 32.31it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    feature_num_r = list(tqdm(p.imap(mp_calc.top_feature_num, range(iter_length)), total=iter_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num_r = np.array(feature_num_r)\n",
    "out_df['rf_top_feature_num'] = feature_num_r[:, 0]\n",
    "out_df['linear_top_feature_num'] = feature_num_r[:, 1]\n",
    "out_df.to_csv('mesc_network_v_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8924062353485036"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(feature_num_r[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 46\n"
     ]
    }
   ],
   "source": [
    "print(len(target_gene_list), len(regulator_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547, 421)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pymc_env]",
   "language": "python",
   "name": "conda-env-pymc_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
