{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts for regression experiments on B.subtilis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mp_run\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_res_df = pd.read_csv('../output/network_model/bsubtilis_all_tf_high_var_target_efron_train.csv.gz', compression='gzip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df_1 = pd.read_csv('../data/bsubtilis/GSE108659/normalized/source.csv.gz', index_col=0, compression='gzip')\n",
    "source_df_2 = pd.read_csv('../data/bsubtilis/GSE128875/normalized/source.csv.gz', index_col=0, compression='gzip')\n",
    "source_df_3 = pd.read_csv('../data/bsubtilis/GSE224332/normalized/source.csv.gz', index_col=0, compression='gzip')\n",
    "target_df_1 = pd.read_csv('../data/bsubtilis/GSE108659/normalized/target.csv.gz', index_col=0, compression='gzip')\n",
    "target_df_2 = pd.read_csv('../data/bsubtilis/GSE128875/normalized/target.csv.gz', index_col=0, compression='gzip')\n",
    "target_df_3 = pd.read_csv('../data/bsubtilis/GSE224332/normalized/target.csv.gz', index_col=0, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_df_1 = pd.read_csv('../data/bsubtilis/GSE108659/normalized/train_source.csv.gz', index_col=0, compression='gzip')\n",
    "train_source_df_2 = pd.read_csv('../data/bsubtilis/GSE128875/normalized/train_source.csv.gz', index_col=0, compression='gzip')\n",
    "train_source_df_3 = pd.read_csv('../data/bsubtilis/GSE224332/normalized/train_source.csv.gz', index_col=0, compression='gzip')\n",
    "train_target_df_1 = pd.read_csv('../data/bsubtilis/GSE108659/normalized/train_target.csv.gz', index_col=0, compression='gzip')\n",
    "train_target_df_2 = pd.read_csv('../data/bsubtilis/GSE128875/normalized/train_target.csv.gz', index_col=0, compression='gzip')\n",
    "train_target_df_3 = pd.read_csv('../data/bsubtilis/GSE224332/normalized/train_target.csv.gz', index_col=0, compression='gzip')\n",
    "\n",
    "test_source_df_1 = pd.read_csv('../data/bsubtilis/GSE108659/normalized/test_source.csv.gz', index_col=0, compression='gzip')\n",
    "test_source_df_2 = pd.read_csv('../data/bsubtilis/GSE128875/normalized/test_source.csv.gz', index_col=0, compression='gzip')\n",
    "test_source_df_3 = pd.read_csv('../data/bsubtilis/GSE224332/normalized/test_source.csv.gz', index_col=0, compression='gzip')\n",
    "test_target_df_1 = pd.read_csv('../data/bsubtilis/GSE108659/normalized/test_target.csv.gz', index_col=0, compression='gzip')\n",
    "test_target_df_2 = pd.read_csv('../data/bsubtilis/GSE128875/normalized/test_target.csv.gz', index_col=0, compression='gzip')\n",
    "test_target_df_3 = pd.read_csv('../data/bsubtilis/GSE224332/normalized/test_target.csv.gz', index_col=0, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulator_set = set()\n",
    "tf_list_df = pd.read_csv('../data/bsubtilis/bsubtilis_tf_list.tsv.gz', sep='\\t', compression='gzip', index_col=0)\n",
    "tf_list_df\n",
    "for name in tf_list_df['Gene Names']:\n",
    "    name_splits = name.split(' ')\n",
    "    for i in name_splits:\n",
    "        if i in source_df_1.index:\n",
    "            regulator_set.add(i)\n",
    "\n",
    "network_df = pd.read_csv('../data/bsubtilis/gs_regulations.csv')\n",
    "regulator_set = regulator_set.union(set(network_df['regulator name']))\n",
    "target_set = set(network_df['gene name'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulator_set = regulator_set.intersection(set(source_df_1.index), set(source_df_2.index), set(source_df_3.index))\n",
    "target_set = target_set.intersection(set(source_df_1.index), set(source_df_2.index), set(source_df_3.index))\n",
    "all_gene_set = regulator_set.union(target_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_dict = {target: [] for target in target_set}\n",
    "for ind, row in network_df.iterrows():\n",
    "    if (row['regulator name'] in regulator_set) and (row['gene name'] in target_set):\n",
    "        network_dict[row['gene name']].append(row['regulator name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = []\n",
    "value_list = []\n",
    "regulator_set = set()\n",
    "target_set = set()\n",
    "for key in network_dict.keys():\n",
    "    if (len(network_dict[key]) > 0):\n",
    "        key_list.append(key)\n",
    "        target_set.add(key)\n",
    "        value_list.append(\"; \".join(network_dict[key]))\n",
    "        for regulator in network_dict[key]:\n",
    "            regulator_set.add(regulator)\n",
    "all_gene_set = regulator_set.union(target_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.DataFrame(index=key_list)\n",
    "network_df['tf_list'] = value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df_1 = source_df_1.loc[list(all_gene_set)]\n",
    "source_df_2 = source_df_2.loc[list(all_gene_set)]\n",
    "source_df_3 = source_df_3.loc[list(all_gene_set)]\n",
    "target_df_1 = target_df_1.loc[list(all_gene_set)]\n",
    "target_df_2 = target_df_2.loc[list(all_gene_set)]\n",
    "target_df_3 = target_df_3.loc[list(all_gene_set)]\n",
    "\n",
    "train_source_df_1 = train_source_df_1.loc[list(all_gene_set)]\n",
    "train_source_df_2 = train_source_df_2.loc[list(all_gene_set)]\n",
    "train_source_df_3 = train_source_df_3.loc[list(all_gene_set)]\n",
    "train_target_df_1 = train_target_df_1.loc[list(all_gene_set)]\n",
    "train_target_df_2 = train_target_df_2.loc[list(all_gene_set)]\n",
    "train_target_df_3 = train_target_df_3.loc[list(all_gene_set)]\n",
    "\n",
    "test_source_df_1 = test_source_df_1.loc[list(all_gene_set)]\n",
    "test_source_df_2 = test_source_df_2.loc[list(all_gene_set)]\n",
    "test_source_df_3 = test_source_df_3.loc[list(all_gene_set)]\n",
    "test_target_df_1 = test_target_df_1.loc[list(all_gene_set)]\n",
    "test_target_df_2 = test_target_df_2.loc[list(all_gene_set)]\n",
    "test_target_df_3 = test_target_df_3.loc[list(all_gene_set)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = pd.concat([train_source_df_1, train_source_df_2, train_source_df_3], axis=1).apply(stats.zscore, axis=0)\n",
    "test_source = pd.concat([test_source_df_1, test_source_df_2, test_source_df_3], axis=1).apply(stats.zscore, axis=0)\n",
    "train_target = pd.concat([train_target_df_1, train_target_df_2, train_target_df_3], axis=1).apply(stats.zscore, axis=0)\n",
    "test_target = pd.concat([test_target_df_1, test_target_df_2, test_target_df_3], axis=1).apply(stats.zscore, axis=0)\n",
    "\n",
    "target_df = pd.concat([target_df_1, target_df_2, target_df_3], axis=1).apply(stats.zscore, axis=0)\n",
    "source_df = pd.concat([source_df_1, source_df_2, source_df_3], axis=1).apply(stats.zscore, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_list = [train_source_df_1, train_source_df_2, train_source_df_3]\n",
    "train_target_list = [train_target_df_1, train_target_df_2, train_target_df_3]\n",
    "test_source_list = [test_source_df_1, test_source_df_2, test_source_df_3]\n",
    "test_target_list = [test_target_df_1, test_target_df_2, test_target_df_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in list(target_set):\n",
    "    if len(network_df.loc[a]['tf_list'].split('; ')) < 1 or network_df.loc[a]['tf_list'] == a:\n",
    "        target_set.remove(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TFs used:\n",
      "151\n"
     ]
    }
   ],
   "source": [
    "print('Number of TFs used:')\n",
    "print(len(regulator_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_gene_list = list(target_set)\n",
    "target_exp = target_df\n",
    "X = source_df.loc[list(regulator_set)]\n",
    "tf_list = list(regulator_set)\n",
    "target_gene_list = list(ref_res_df.index)\n",
    "tf_list_df = pd.read_csv('../output/network_model/bsubtilis_tf.csv', names=['tf'], index_col=0)\n",
    "tf_list = list(tf_list_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 733/733 [00:53<00:00, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7265870307819318\n",
      "-15820.287820229965\n",
      "======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 733/733 [01:08<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8011109732265792\n",
      "-132.38151844454012\n",
      "======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 733/733 [01:06<00:00, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2809305377298625\n",
      "-151.61205917451406\n",
      "======================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_source_list)):\n",
    "    cv_test_source = pd.concat([train_source_list[i], test_source_list[i]], axis=1)\n",
    "    cv_test_target = pd.concat([train_target_list[i], test_target_list[i]], axis=1)\n",
    "    cv_train_source_cur = []\n",
    "    cv_train_target_cur = []\n",
    "    for j in range(len(train_source_list)):\n",
    "        if i == j: continue\n",
    "        cv_train_source_cur.append(train_source_list[j])\n",
    "        cv_train_source_cur.append(test_source_list[j])\n",
    "        cv_train_target_cur.append(train_target_list[j])\n",
    "        cv_train_target_cur.append(test_target_list[j])\n",
    "    cv_train_source = pd.concat(cv_train_source_cur, axis=1)\n",
    "    cv_train_target = pd.concat(cv_train_target_cur, axis=1)\n",
    "    mp_calc = mp_run.MpCalc(target_gene_list, X, network_df, cv_train_source.loc[tf_list], cv_train_target, cv_test_source.loc[tf_list], cv_test_target)\n",
    "    iter_length = len(target_gene_list)\n",
    "    with Pool(cpu_count()) as p:\n",
    "        r = list(tqdm(p.imap(mp_calc.full_comp_new, range(iter_length)), total=iter_length))\n",
    "    r = np.array(r)\n",
    "    out_df = pd.DataFrame(index=target_gene_list)\n",
    "    out_df['rf_score'] = r[:, 0]\n",
    "    out_df['linear_score'] = r[:, 1]\n",
    "    out_df['gs_rf_score'] = r[:, 2]\n",
    "    out_df['gs_linear_score'] = r[:, 3]\n",
    "    out_df['rf_with_linear_top_features_score'] = r[:, 4]\n",
    "    out_df['linear_with_rf_top_features_score'] = r[:, 5]\n",
    "    out_df['rf_rmse'] = r[:, 6]\n",
    "    out_df['linear_rmse'] = r[:, 7]\n",
    "    out_df['gs_rf_rmse'] = r[:, 8]\n",
    "    out_df['gs_linear_rmse'] = r[:, 9]\n",
    "    out_df['rf_with_linear_top_features_rmse'] = r[:, 10]\n",
    "    out_df['linear_with_rf_top_features_rmse'] = r[:, 11]\n",
    "    out_df['rf_with_top_features_score'] = r[:, 12]\n",
    "    out_df['linear_with_top_features_score'] = r[:, 13]\n",
    "    out_df['rf_with_top_features_rmse'] = r[:, 14]\n",
    "    out_df['linear_with_top_features_rmse'] = r[:, 15]\n",
    "    out_df['rf_top_feature_num'] = r[:, 16]\n",
    "    out_df['linear_top_feature_num'] = r[:, 17]\n",
    "    out_df['rf_top_features_gs_overlap'] = r[:, 18]\n",
    "    out_df['linear_top_features_gs_overlap'] = r[:, 19]\n",
    "    out_df['rf_linear_top_features_overlap'] = r[:, 20]\n",
    "    out_df['gs_edge_num'] = r[:, 21]\n",
    "    out_df['test_var'] = r[:, 22]\n",
    "    out_df['test_std'] = r[:, 23]\n",
    "    out_df['pca_rf_score'] = r[:, 24]\n",
    "    out_df['pca_rf_rmse'] = r[:, 25]\n",
    "    \n",
    "    print(out_df['rf_rmse'].mean())\n",
    "    print(out_df['rf_score'].mean())\n",
    "    print('======================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
