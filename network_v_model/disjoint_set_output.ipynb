{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "1fa7b794-1193-4ac2-a7dc-04456168123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from scipy.integrate import simpson\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from conf_interval import conf_interval_calc\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pairedtest import pairedtest\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':200})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d5f45708-ae0b-49dd-ab6a-d4935728656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']\n",
    "\n",
    "disjoint_set_size_threshold = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7844e80-d321-42e5-bb46-7b31817dd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df_list = [\n",
    "    pd.read_csv('../output/network_model/yeast_tf.csv', index_col=0, names=['tf']),\n",
    "    pd.read_csv('../output/network_model/bsubtilis_tf.csv', index_col=0, names=['tf']),\n",
    "    pd.read_csv('../output/network_model/arabidopsis_tf.csv', index_col=0, names=['tf']),\n",
    "    pd.read_csv('../output/network_model/mouse_tf.csv', index_col=0, names=['tf']),\n",
    "]\n",
    "\n",
    "res_df_list = [\n",
    "    pd.read_csv('../output/network_model/yeast_all_tf_high_var_target_efron_train.csv.gz', index_col=0, compression='gzip'),\n",
    "    pd.read_csv('../output/network_model/bsubtilis_all_tf_high_var_target_efron_train.csv.gz', index_col=0, compression='gzip'),\n",
    "    pd.read_csv('../output/network_model/arabidopsis_all_tf_high_var_target_efron_train.csv.gz', index_col=0, compression='gzip'),\n",
    "    pd.read_csv('../output/network_model/mouse_all_tf_high_var_target_efron_train.csv.gz', index_col=0, compression='gzip'),\n",
    "]\n",
    "species_file_names = ['yeast', 'bsubtilis', 'arabidopsis', 'mouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87a2b488-71a6-4661-8f45-6fb6b865c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2152906/491479083.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['disjoint_sets'] = disjoint_sets_list\n",
      "/tmp/ipykernel_2152906/491479083.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['minimal_set'] = minimal_sets_list\n",
      "/tmp/ipykernel_2152906/491479083.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['disjoint_sets'] = disjoint_sets_list\n",
      "/tmp/ipykernel_2152906/491479083.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['minimal_set'] = minimal_sets_list\n",
      "/tmp/ipykernel_2152906/491479083.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['disjoint_sets'] = disjoint_sets_list\n",
      "/tmp/ipykernel_2152906/491479083.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['minimal_set'] = minimal_sets_list\n",
      "/tmp/ipykernel_2152906/491479083.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['disjoint_sets'] = disjoint_sets_list\n",
      "/tmp/ipykernel_2152906/491479083.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  out_df['minimal_set'] = minimal_sets_list\n"
     ]
    }
   ],
   "source": [
    "for res_df, tf_list, species_file_name in zip(res_df_list, tf_df_list, species_file_names):\n",
    "    out_df = res_df[['rf_rmse', 'test_std', 'rf_efron_features', 'rf_efron_complementary_features_list']]\n",
    "    disjoint_sets_list = []\n",
    "    minimal_sets_list = []\n",
    "    for i, row in out_df.iterrows():\n",
    "        first_set = row['rf_efron_features'].split('; ')\n",
    "        first_set = ': '.join([tf_list.index[int(j)] for j in first_set])\n",
    "        minimal_sets_list.append(first_set)\n",
    "        disjoint_sets = [first_set]\n",
    "        if isinstance(row['rf_efron_complementary_features_list'], str):\n",
    "            rest_of_sets = row['rf_efron_complementary_features_list'].split(', ')\n",
    "            for disjoint_set in rest_of_sets:\n",
    "                disjoint_sets.append(': '.join([tf_list.index[int(j)] for j in disjoint_set.split('; ')]))\n",
    "        # print(disjoint_sets)\n",
    "        # break\n",
    "        disjoint_sets_list.append('; '.join(disjoint_sets))\n",
    "    out_df['disjoint_sets'] = disjoint_sets_list\n",
    "    out_df['minimal_set'] = minimal_sets_list\n",
    "    out_df.index.name = 'target_gene'\n",
    "    out_df[['minimal_set', 'disjoint_sets']].to_csv('../output/network_model/{}_disjoint_sets.csv'.format(species_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c8f8f69a-fd38-4be4-9fc9-75f5dc95b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.read_csv('../output/network_model/arabidopsis_all_tf_high_var_target_efron_train.csv.gz', index_col=0, compression='gzip')\n",
    "tf_list = pd.read_csv('../output/network_model/arabidopsis_tf.csv', index_col=0, names=['tf'])\n",
    "out_df = res_df[['rf_rmse', 'test_std', 'rf_efron_features', 'rf_efron_complementary_features_list']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0b8939c6-a740-4770-af49-178833a42a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_genes = pd.read_csv('../data/arabidopsis_nitro_pathway.tsv.gz', sep='\\t', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "eb6dc1ed-78b6-4a12-a467-4beea1a28672",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_names = pathway_genes[pathway_genes['Gene Names'].notna()]['Gene Names'].values\n",
    "gene_names = [s.split(' ') for s in gene_names]\n",
    "gene_names = [\n",
    "    x.upper()\n",
    "    for xs in gene_names\n",
    "    for x in xs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "28fc3a53-b75e-454e-a015-057ee121e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_matches = []\n",
    "for ind in out_df.index:\n",
    "    if ind in gene_names:\n",
    "        pathway_matches.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ec738fb3-cec4-4a54-aa72-247f12fce6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_df.loc[pathway_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6dd73cf9-2da3-4c94-8450-9a7fbf07ece6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      AT3G26680\n",
       "1      AT3G26680\n",
       "2      AT5G65720\n",
       "3      AT1G02860\n",
       "4      AT1G53310\n",
       "         ...    \n",
       "101    AT1G10010\n",
       "102    AT5G50950\n",
       "103    AT4G24670\n",
       "104    AT5G57390\n",
       "105    AT3G03910\n",
       "Name: Locus, Length: 106, dtype: object"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tair_genes = pd.read_csv('../data/tair_nitrogen.csv', sep='\\t')\n",
    "tair_genes['Locus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c1157c5f-c7d3-48cd-84c2-24fdd0a432c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_matches = []\n",
    "for ind in out_df.index:\n",
    "    if ind in tair_genes['Locus'].values:\n",
    "        pathway_matches.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "7dbe567e-a108-4195-81f6-594c204bb12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_df.loc[pathway_matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "bacd17f7-2236-4c32-b742-a8001eda63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "disjoint_sets_list = []\n",
    "disjoint_sets_dict = {}\n",
    "minimal_sets_list = []\n",
    "for i, row in out_df.iterrows():\n",
    "    first_set = row['rf_efron_features'].split('; ')\n",
    "    first_set = set([int(i) for i in first_set])\n",
    "    # first_set = ': '.join([tf_list.index[int(j)] for j in first_set])\n",
    "    minimal_sets_list.append(first_set)\n",
    "    if (len(first_set) > disjoint_set_size_threshold):\n",
    "        disjoint_sets = []\n",
    "    else:\n",
    "        disjoint_sets = [first_set]\n",
    "    if isinstance(row['rf_efron_complementary_features_list'], str):\n",
    "        rest_of_sets = row['rf_efron_complementary_features_list'].split(', ')\n",
    "        for n_set in rest_of_sets:\n",
    "            disjoint_set = n_set.split('; ')\n",
    "            disjoint_set = set([int(i) for i in disjoint_set])\n",
    "            if (len(disjoint_set) <= disjoint_set_size_threshold):\n",
    "                disjoint_sets.append(disjoint_set)\n",
    "    # print(disjoint_sets)\n",
    "    # break\n",
    "    if (len(disjoint_sets) > 0):\n",
    "        disjoint_sets_list.append(disjoint_sets)\n",
    "        disjoint_sets_dict[i] = disjoint_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8a7531b3-05cf-4322-a377-5ce6c56d05e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_occur_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "e1ca7947-1b72-4792-9cbf-fd7331738499",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disjoint_sets in disjoint_sets_list:\n",
    "    for disjoint_set in disjoint_sets:\n",
    "        for tf in disjoint_set:\n",
    "            if tf in tf_occur_count:\n",
    "                tf_occur_count[tf] += 1\n",
    "            else: tf_occur_count[tf] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "293b54e4-82b9-40cc-8c35-0f1a4019df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_occur_count = dict(sorted(tf_occur_count.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "59dcd257-1c17-4e70-8d8f-89eca342acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_union_set = set(tf_occur_count.keys())\n",
    "sorted_tf_list = [i for i in tf_occur_count.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "59925f32-4f37-4fd2-a526-f518ae09e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_flag = True\n",
    "tf_remove_index = 0\n",
    "while (continue_flag):\n",
    "    for disjoint_sets in disjoint_sets_list:\n",
    "        should_continue = False\n",
    "        for disjoint_set in disjoint_sets:\n",
    "            if len(disjoint_set.intersection(tf_union_set)) == len(disjoint_set):\n",
    "                should_continue = True\n",
    "                break\n",
    "        if not should_continue:\n",
    "            continue_flag = False\n",
    "            break\n",
    "    if continue_flag:\n",
    "        tf_union_set.remove(sorted_tf_list[tf_remove_index])\n",
    "        tf_remove_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "724226cf-7e03-40aa-9a4d-970cda97f0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_occur_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "cab3457b-282a-441f-8bb0-d022ec954e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "covered_targets = set()\n",
    "remaining_targets = set(disjoint_sets_dict.keys())\n",
    "used_tf = set()\n",
    "tf_add_index = -1\n",
    "while (len(remaining_targets)>0):\n",
    "    used_tf.add(sorted_tf_list[tf_add_index])\n",
    "    target_search_list = copy.deepcopy(list(remaining_targets))\n",
    "    for target in target_search_list:\n",
    "        for dj_set in disjoint_sets_dict[target]:\n",
    "            if len(dj_set.intersection(used_tf)) == len(dj_set):\n",
    "                remaining_targets.remove(target)\n",
    "                covered_targets.add(target)\n",
    "                break\n",
    "    tf_add_index -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "7f042608-5a57-4ed5-88c3-cd5b217fbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_tf_occur_count = {key: tf_occur_count[key] for key in used_tf}\n",
    "used_tf_occur_count = dict(sorted(used_tf_occur_count.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "07f63036-b5df-48d8-b396-a605b4ea9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "used_sorted_tf_list = [i for i in used_tf_occur_count.keys()]\n",
    "used_tf_union_set = set(used_tf_occur_count.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "94242557-1b0d-40dd-84f9-e5011838d287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_tf_union_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b8617145-5829-4509-889a-fbda9e66ada7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1931"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_sorted_tf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "c944c483-16c2-4f5f-bc44-f0d28d881686",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_flag = True\n",
    "tf_remove_index = 0\n",
    "while (tf_remove_index < len(used_sorted_tf_list)):\n",
    "    continue_flag = True\n",
    "    new_tf_set = copy.deepcopy(used_tf_union_set)\n",
    "    new_tf_set.remove(used_sorted_tf_list[tf_remove_index])\n",
    "    for disjoint_sets in disjoint_sets_list:\n",
    "        should_continue = False\n",
    "        for disjoint_set in disjoint_sets:\n",
    "            if len(disjoint_set.intersection(new_tf_set)) == len(disjoint_set):\n",
    "                should_continue = True\n",
    "                break\n",
    "        if not should_continue:\n",
    "            continue_flag = False\n",
    "            break\n",
    "    if continue_flag:\n",
    "        used_tf_union_set = new_tf_set\n",
    "    tf_remove_index += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "27520fac-6887-4c0b-817a-8432ebb77435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(used_tf_union_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8b7843eb-6fff-4da1-b06a-2ae97cc92f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1397, 4)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4da361-4a6b-4ae3-a7fd-c0932e57c5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pymc_env]",
   "language": "python",
   "name": "conda-env-pymc_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
