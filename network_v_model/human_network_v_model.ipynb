{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts for regression experiments on mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import mp_run\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_1 = pd.read_csv('../data/human/GSE221103/normalized/train_source.csv.gz', index_col=0, compression='gzip')\n",
    "train_target_1 = pd.read_csv('../data/human/GSE221103/normalized/train_target.csv.gz', index_col=0, compression='gzip')\n",
    "test_source_1 = pd.read_csv('../data/human/GSE221103/normalized/test_source.csv.gz', index_col=0, compression='gzip')\n",
    "test_target_1 = pd.read_csv('../data/human/GSE221103/normalized/test_target.csv.gz', index_col=0, compression='gzip')\n",
    "\n",
    "train_source_2 = pd.read_csv('../data/human/GSE221173/normalized/train_source.csv.gz', index_col=0, compression='gzip')\n",
    "train_target_2 = pd.read_csv('../data/human/GSE221173/normalized/train_target.csv.gz', index_col=0, compression='gzip')\n",
    "test_source_2 = pd.read_csv('../data/human/GSE221173/normalized/test_source.csv.gz', index_col=0, compression='gzip')\n",
    "test_target_2 = pd.read_csv('../data/human/GSE221173/normalized/test_target.csv.gz', index_col=0, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_exp_genes = list(set(train_source_1.index).intersection(set(train_source_2.index)))\n",
    "\n",
    "train_source_1 = train_source_1.loc[common_exp_genes]\n",
    "train_target_1 = train_target_1.loc[common_exp_genes]\n",
    "test_source_1 = test_source_1.loc[common_exp_genes]\n",
    "test_target_1 = test_target_1.loc[common_exp_genes]\n",
    "\n",
    "train_source_2 = train_source_2.loc[common_exp_genes]\n",
    "train_target_2 = train_target_2.loc[common_exp_genes]\n",
    "test_source_2 = test_source_2.loc[common_exp_genes]\n",
    "test_target_2 = test_target_2.loc[common_exp_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59276"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_exp_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = pd.concat([train_source_1, train_source_2], axis=1)\n",
    "train_target = pd.concat([train_target_1, train_target_2], axis=1)\n",
    "test_source = pd.concat([test_source_1, test_source_2], axis=1)\n",
    "test_target = pd.concat([test_target_1, test_target_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TFs used:\n",
      "3869\n"
     ]
    }
   ],
   "source": [
    "network_df = pd.read_csv('../data/human/regnetworkweb.org.network', sep='\\t')\n",
    "regulator_set = set(network_df['regulator'])\n",
    "target_set = set(network_df['target'])\n",
    "\n",
    "regulator_set = regulator_set.intersection(set(train_source.index))\n",
    "target_set = target_set.intersection(set(train_source.index))\n",
    "all_gene_set = regulator_set.union(target_set)\n",
    "network_dict = {target: [] for target in target_set}\n",
    "for ind, row in network_df.iterrows():\n",
    "    if (row['regulator'] in regulator_set) and (row['target'] in target_set):\n",
    "        network_dict[row['target']].append(row['regulator'])\n",
    "\n",
    "key_list = []\n",
    "value_list = []\n",
    "regulator_set = set()\n",
    "tf_list_df = pd.read_csv('../data/human/human_tf_list.tsv.gz', sep='\\t', compression='gzip', index_col=0)\n",
    "for name in tf_list_df['Gene Names']:\n",
    "    name_splits = str(name).split(' ')\n",
    "    for i in name_splits:\n",
    "        if i in train_source.index:\n",
    "            regulator_set.add(i)\n",
    "target_set = set()\n",
    "for key in network_dict.keys():\n",
    "    if (len(network_dict[key]) > 0) and network_dict[key][0] != key:\n",
    "        key_list.append(key)\n",
    "        target_set.add(key)\n",
    "        value_list.append(\"; \".join(network_dict[key]))\n",
    "        for regulator in network_dict[key]:\n",
    "            regulator_set.add(regulator)\n",
    "all_gene_set = regulator_set.union(target_set)\n",
    "\n",
    "print('Number of TFs used:')\n",
    "print(len(regulator_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_df = pd.read_csv('../data/mouse/regnetworkweb.org.network', sep='\\t')\n",
    "# regulator_set = set(network_df['regulator'])\n",
    "# target_set = set(network_df['target'])\n",
    "\n",
    "# regulator_set = regulator_set.intersection(set(train_source.index))\n",
    "# target_set = target_set.intersection(set(train_source.index))\n",
    "# all_gene_set = regulator_set.union(target_set)\n",
    "# network_dict = {target: [] for target in target_set}\n",
    "# for ind, row in network_df.iterrows():\n",
    "#     if (row['regulator'] in regulator_set) and (row['target'] in target_set):\n",
    "#         network_dict[row['target']].append(row['regulator'])\n",
    "\n",
    "# key_list = []\n",
    "# value_list = []\n",
    "# regulator_set = set()\n",
    "# target_set = set()\n",
    "# for key in network_dict.keys():\n",
    "#     if (len(network_dict[key]) > 0) and network_dict[key][0] != key:\n",
    "#         key_list.append(key)\n",
    "#         target_set.add(key)\n",
    "#         value_list.append(\"; \".join(network_dict[key]))\n",
    "#         for regulator in network_dict[key]:\n",
    "#             regulator_set.add(regulator)\n",
    "# all_gene_set = regulator_set.union(target_set)\n",
    "\n",
    "\n",
    "# print(len(regulator_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.DataFrame(index=key_list)\n",
    "network_df['tf_list'] = value_list\n",
    "target_df = pd.concat([train_target, test_target], axis=1)\n",
    "source_df = pd.concat([train_source, test_source], axis=1)\n",
    "\n",
    "\n",
    "target_gene_list = list(target_set)\n",
    "target_exp = target_df.loc[target_gene_list]\n",
    "X = source_df.loc[list(regulator_set)]\n",
    "tf_list = list(regulator_set)\n",
    "\n",
    "tf_file = Path(\"../output/network_model/human_tf.csv\")\n",
    "if tf_file.is_file():\n",
    "    tf_list_df = pd.read_csv('../output/network_model/human_tf.csv', names=['tf'], index_col=0)\n",
    "    tf_list = list(tf_list_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS edge count:\n",
      "132259\n",
      "Number of TFs in GS:\n",
      "1351\n",
      "Number of target genes in GS:\n",
      "17533\n"
     ]
    }
   ],
   "source": [
    "# GS stats\n",
    "edge_count = 0\n",
    "gs_tf_set = set()\n",
    "gs_target_set = set()\n",
    "for i, row in network_df.iterrows():\n",
    "    if i in target_gene_list:\n",
    "        cur_tf_list = row.tf_list\n",
    "        gs_target_set.add(i)\n",
    "        if pd.isnull(cur_tf_list): \n",
    "            continue\n",
    "        cur_tf_list = cur_tf_list.split('; ')\n",
    "        for cur_tf in cur_tf_list:\n",
    "            if cur_tf in tf_list:\n",
    "                gs_tf_set.add(cur_tf)\n",
    "                edge_count += 1\n",
    "print('GS edge count:')\n",
    "print(edge_count)\n",
    "print('Number of TFs in GS:')\n",
    "print(len(gs_tf_set))\n",
    "print('Number of target genes in GS:')\n",
    "print(len(gs_target_set))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for high variance targets\n",
    "new_test_target = test_target.loc[target_gene_list]\n",
    "new_test_target = new_test_target.loc[new_test_target.std(axis=1) > 0.5]\n",
    "target_gene_list = new_test_target.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size:\n",
      "(59276, 109)\n",
      "testing set size:\n",
      "(59276, 40)\n"
     ]
    }
   ],
   "source": [
    "print('training set size:')\n",
    "print(train_source.shape)\n",
    "print('testing set size:')\n",
    "print(test_source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up MP for calculations\n",
    "mp_calc = mp_run.MpCalc(target_gene_list, X, network_df, train_source.loc[tf_list], train_target, test_source.loc[tf_list], test_target)\n",
    "pd.DataFrame(index=mp_calc.tf_list).to_csv('../output/network_model/human_tf.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing different regression approaches... ...\n",
      "Step 1 of 3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 123/698 [00:36<02:49,  3.39it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.11/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n\u001b[1;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/bingran/code/feature_synergy/network_v_model/human_network_v_model.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/bingran/code/feature_synergy/network_v_model/human_network_v_model.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Doing all calculations \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/bingran/code/feature_synergy/network_v_model/human_network_v_model.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mp_calc\u001b[39m.\u001b[39mfull_comp_runner(target_gene_list, \u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/code/feature_synergy/network_v_model/mp_run.py:797\u001b[0m, in \u001b[0;36mMpCalc.full_comp_runner\u001b[0;34m(self, target_gene_list, species_name)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStep 1 of 3:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    796\u001b[0m \u001b[39mwith\u001b[39;00m Pool(cpu_count()) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m--> 797\u001b[0m     r \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(tqdm(p\u001b[39m.\u001b[39mimap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_comp_new, \u001b[39mrange\u001b[39m(iter_length)), total\u001b[39m=\u001b[39miter_length))\n\u001b[1;32m    798\u001b[0m r \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(r)\n\u001b[1;32m    799\u001b[0m out_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(index\u001b[39m=\u001b[39mtarget_gene_list)\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.11/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    862\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/anaconda3/envs/pymc_env/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    328\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Doing all calculations \n",
    "mp_calc.full_comp_runner(target_gene_list, 'human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
