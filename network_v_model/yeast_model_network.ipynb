{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "import mp_run\n",
    "import conf_interval\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts training/testing data curation \n",
    "\n",
    "df_1 = pd.read_csv('../data/yeast/GSE145936_Sis1-AA_Gene_counts_normalized.txt', sep='\\t', index_col=0)\n",
    "df_2 = pd.read_csv('../data/yeast/GSE153609_gene_expression_TPM_all_times.csv', index_col=0)\n",
    "df_3 = pd.read_csv('../data/yeast/GSE168699_RNA_TPM_all_times.csv', index_col=0)\n",
    "\n",
    "to_drop = df_3.columns[:7]\n",
    "df_3 = df_3.drop(labels=to_drop, axis=1)\n",
    "df_1 = df_1.drop(labels=['gene name'], axis=1)\n",
    "\n",
    "common_genes = set(df_1.index).intersection(set(df_2.index)).intersection(set(df_3.index))\n",
    "common_genes = list(common_genes)\n",
    "# normalized_df_1=(df_1-df_1.min())/(df_1.max()-df_1.min())\n",
    "# normalized_df_2=(df_2-df_2.min())/(df_2.max()-df_2.min())\n",
    "# normalized_df_3=(df_3-df_3.min())/(df_3.max()-df_3.min())\n",
    "normalized_df_1=df_1.apply(stats.zscore, axis=0)\n",
    "normalized_df_2=df_2.apply(stats.zscore, axis=0)\n",
    "normalized_df_3=df_3.apply(stats.zscore, axis=0)\n",
    "# normalized_df_1 = normalized_df_1*100.0\n",
    "# normalized_df_2 = normalized_df_2*100.0\n",
    "# normalized_df_3 = normalized_df_3*100.0\n",
    "normalized_df_1 = normalized_df_1.loc[common_genes]\n",
    "normalized_df_2 = normalized_df_2.loc[common_genes]\n",
    "normalized_df_3 = normalized_df_3.loc[common_genes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_source_target_split(df, time_set, rep_set):\n",
    "    sorted_time_list = sorted(time_set, key=lambda time_str: float(re.search(number_pattern, time_str).group(1)))\n",
    "    print(sorted_time_list)\n",
    "\n",
    "    train_source_time = sorted_time_list[:-2]\n",
    "    train_target_time = sorted_time_list[1:-1]\n",
    "    test_source_time = sorted_time_list[-2:-1]\n",
    "    test_target_time = sorted_time_list[-1:]\n",
    "\n",
    "    train_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_source_time)]\n",
    "    train_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_target_time)]\n",
    "    test_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_source_time)]\n",
    "    test_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_target_time)]\n",
    "    return df[train_source_list], df[train_target_list], df[test_source_list], df[test_target_list]\n",
    "\n",
    "def format_index_and_normalize(df):\n",
    "    normalized_df = df.apply(stats.zscore, axis=0)\n",
    "    selected_index_list = []\n",
    "    new_index_list = []\n",
    "    for index_name in df.index:\n",
    "        names = index_name.split('Name=')[-1]\n",
    "        if ('/' in names):\n",
    "            name_list = names.split('/')[:2]\n",
    "            for name in name_list:\n",
    "                if (name in common_genes):\n",
    "                    selected_index_list.append(index_name)\n",
    "                    new_index_list.append(name)\n",
    "                    continue\n",
    "        elif (names in common_genes):\n",
    "            selected_index_list.append(index_name)\n",
    "            new_index_list.append(names)\n",
    "            continue\n",
    "    len(new_index_list)\n",
    "    new_df = normalized_df.loc[selected_index_list]\n",
    "    new_df.index = new_index_list\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_1 = pd.read_csv('../data/yeast/GSE226769/GSE226769_Meiotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_1 = format_index_and_normalize(df_0_1)\n",
    "df_0_2 = pd.read_csv('../data/yeast/GSE226769/GSE226769_Mitotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_2 = df_0_2.drop(columns=df_0_2.columns[-6:])\n",
    "df_0_2 = format_index_and_normalize(df_0_2)\n",
    "df_0_3 = pd.read_csv('../data/yeast/GSE226769/GSE226769_UME6_T99N_AltAD_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_3 = format_index_and_normalize(df_0_3)\n",
    "df_0_4 = pd.read_csv('../data/yeast/GSE226769/GSE226769_UME6_T99N_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_4 = format_index_and_normalize(df_0_4)\n",
    "\n",
    "common_genes = set(common_genes).intersection(set(df_0_1.index), set(df_0_2.index), set(df_0_3.index), set(df_0_4.index))\n",
    "common_genes = list(common_genes)\n",
    "df_0_1 = df_0_1.loc[common_genes]\n",
    "df_0_2 = df_0_2.loc[common_genes]\n",
    "df_0_3 = df_0_3.loc[common_genes]\n",
    "df_0_4 = df_0_4.loc[common_genes]\n",
    "df_0_1 = df_0_1[~df_0_1.index.duplicated(keep='first')]\n",
    "df_0_2 = df_0_2[~df_0_2.index.duplicated(keep='first')]\n",
    "df_0_3 = df_0_3[~df_0_3.index.duplicated(keep='first')]\n",
    "df_0_4 = df_0_4[~df_0_4.index.duplicated(keep='first')]\n",
    "normalized_df_1 = normalized_df_1.loc[common_genes]\n",
    "normalized_df_2 = normalized_df_2.loc[common_genes]\n",
    "normalized_df_3 = normalized_df_3.loc[common_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "['0.5HR', '2HR', '2.5HR', '3HR', '4.5HR', '6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_1.columns:\n",
    "    name_segments = name.split('_')\n",
    "    rep_name = ''.join(name_segments[:-1])\n",
    "    time_name = name_segments[-1]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_1.columns = formated_name_list\n",
    "normalized_df = df_0_1.apply(stats.zscore, axis=0)\n",
    "df_split_1 = train_test_source_target_split(normalized_df, time_set, rep_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-30min', '0min', '15min', '30min', '60min', '120min']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_2.columns:\n",
    "    pattern = r'(.*)\\(([^()]*)\\)(.*)' \n",
    "    match = re.match(pattern, name)\n",
    "    rep_name = match.group(1) + match.group(3)\n",
    "    rep_set.add(rep_name)\n",
    "    time_name = match.group(2)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "df_0_2.columns = formated_name_list\n",
    "normalized_df = df_0_2.apply(stats.zscore, axis=0)\n",
    "df_split_2 = train_test_source_target_split(normalized_df, time_set, rep_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 4\n",
      "['0HR', '2HR', '4HR', '6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_3.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_3.columns = formated_name_list\n",
    "normalized_df = df_0_3.apply(stats.zscore, axis=0)\n",
    "df_split_3 = train_test_source_target_split(normalized_df, time_set, rep_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 4\n",
      "[' 0HR', ' 2HR', ' 4HR', ' 6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_4.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_4.columns = formated_name_list\n",
    "normalized_df = df_0_4.apply(stats.zscore, axis=0)\n",
    "df_split_4 = train_test_source_target_split(normalized_df, time_set, rep_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_df_1 = normalized_df_1.iloc[:,[3,4,5,9,10,11]]\n",
    "test_df_2 = normalized_df_2.iloc[:,[3,4,5]]\n",
    "test_df_3 = normalized_df_3.iloc[:, -5:]\n",
    "test_exp = pd.concat([test_df_1, test_df_2, test_df_3], axis=1)\n",
    "test_source = test_exp.iloc[:,[0,1,3,4,6,7,9,10,11,12]]\n",
    "test_target = test_exp.iloc[:,[0,1,3,4,6,7,9,10,11,12]]\n",
    "\n",
    "train_source_df_1 = normalized_df_1.iloc[:, [0,1,2,3,5,6,7,8,9]]\n",
    "train_target_df_1 = normalized_df_1.iloc[:, [1,2,3,4,6,7,8,9,10]]\n",
    "train_source_df_2 = normalized_df_2.iloc[:, [0,1,2,3]]\n",
    "train_target_df_2 = normalized_df_2.iloc[:, [1,2,3,4]]\n",
    "\n",
    "train_source_df_3 = normalized_df_3.iloc[:, :-4]\n",
    "train_target_df_3 = normalized_df_3.iloc[:, 1:-3]\n",
    "train_source = pd.concat([train_source_df_1, train_source_df_2, train_source_df_3], axis=1)\n",
    "train_target = pd.concat([train_target_df_1, train_target_df_2, train_target_df_3], axis=1)\n",
    "source_exp = pd.concat([train_source, test_source], axis=1)\n",
    "target_exp = pd.concat([train_target, test_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = pd.concat([train_source, df_split_1[0], df_split_2[0], df_split_3[0], df_split_4[0]], axis=1)\n",
    "train_target = pd.concat([train_target, df_split_1[1], df_split_2[1], df_split_3[1], df_split_4[1]], axis=1)\n",
    "test_source = pd.concat([test_source, df_split_1[2], df_split_2[2], df_split_3[2], df_split_4[2]], axis=1)\n",
    "test_target = pd.concat([test_target, df_split_1[3], df_split_2[3], df_split_3[3], df_split_4[3]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get network data, training features\n",
    "network_df = pd.read_csv('./yeat_network.csv', index_col=0)\n",
    "tf_set = set()\n",
    "target_gene_list = []\n",
    "for i, row in network_df.iterrows():\n",
    "    tf_list = row.tf_list\n",
    "    if pd.isnull(tf_list): \n",
    "        continue\n",
    "    tf_list = tf_list.split('; ')\n",
    "    tf_set = tf_set.union(set(tf_list))\n",
    "    target_gene_list.append(i)\n",
    "\n",
    "target_gene_list = list(set(target_gene_list).intersection(set(common_genes)))\n",
    "# filterout NaN target:\n",
    "target_gene_list = list(target_exp.loc[target_gene_list][target_exp.loc[target_gene_list].isnull().any(axis=1)==False].index)\n",
    "tf_list = list(tf_set.intersection(set(common_genes)))\n",
    "\n",
    "X = source_exp.loc[tf_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_var_target_genes = set(normalized_df_1.var(axis=1).sort_values(ascending=False).head(500).index).intersection(\n",
    "    set(normalized_df_2.var(axis=1).sort_values(ascending=False).head(500).index)).intersection(\n",
    "    set(normalized_df_3.var(axis=1).sort_values(ascending=False).head(500).index))\n",
    "high_var_target_genes = high_var_target_genes.difference(set(tf_list))\n",
    "\n",
    "high_var_target_genes = list(high_var_target_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_calc = mp_run.MpCalc(target_gene_list, target_exp, X, network_df, train_source.loc[tf_list], train_target, test_source.loc[tf_list], test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4794/4794 [07:22<00:00, 10.84it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.full_comp, range(iter_length)), total=iter_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(r)\n",
    "out_df = pd.DataFrame(index=target_gene_list)\n",
    "out_df['rf_score'] = r[:, 0]\n",
    "out_df['linear_score'] = r[:, 1]\n",
    "out_df['gs_rf_score'] = r[:, 2]\n",
    "out_df['gs_linear_score'] = r[:, 3]\n",
    "out_df['rf_with_linear_top_features_score'] = r[:, 4]\n",
    "out_df['linear_with_rf_top_features_score'] = r[:, 5]\n",
    "out_df['rf_rmse'] = r[:, 6]\n",
    "out_df['linear_rmse'] = r[:, 7]\n",
    "out_df['gs_rf_rmse'] = r[:, 8]\n",
    "out_df['gs_linear_rmse'] = r[:, 9]\n",
    "out_df['rf_with_linear_top_features_rmse'] = r[:, 10]\n",
    "out_df['linear_with_rf_top_features_rmse'] = r[:, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4794/4794 [04:37<00:00, 17.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# top 95% important feature count\n",
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    feature_num_r = list(tqdm(p.imap(mp_calc.top_feature_num, range(iter_length)), total=iter_length))\n",
    "feature_num_r = np.array(feature_num_r)\n",
    "\n",
    "out_df['rf_top_feature_num'] = feature_num_r[:, 0]\n",
    "out_df['linear_top_feature_num'] = feature_num_r[:, 1]\n",
    "out_df['test_var'] = test_target.loc[out_df.index].var(axis=1)\n",
    "out_df['test_std'] = test_target.loc[out_df.index].std(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4794/4794 [04:43<00:00, 16.91it/s]\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.read_csv('./yeast_network_v_model.csv', index_col=0)\n",
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    top_feature_r = list(tqdm(p.imap(mp_calc.top_feature_model, range(iter_length)), total=iter_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature_r = np.array(top_feature_r)\n",
    "out_df['rf_with_top_features_score'] = top_feature_r[:, 0]\n",
    "out_df['linear_with_top_features_score'] = top_feature_r[:, 1]\n",
    "out_df['rf_with_top_features_rmse'] = top_feature_r[:, 2]\n",
    "out_df['linear_with_top_features_rmse'] = top_feature_r[:, 3]\n",
    "out_df.to_csv('yeast_network_v_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4794/4794 [04:25<00:00, 18.03it/s]\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.read_csv('./yeast_network_v_model.csv', index_col=0)\n",
    "\n",
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    top_feature_overlap_r = list(tqdm(p.imap(mp_calc.feature_overlap, range(iter_length)), total=iter_length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feature_overlap_r = np.array(top_feature_overlap_r)\n",
    "out_df['rf_top_features_gs_overlap'] = top_feature_overlap_r[:, 0]\n",
    "out_df['linear_top_features_gs_overlap'] = top_feature_overlap_r[:, 1]\n",
    "out_df['rf_linear_top_features_overlap'] = top_feature_overlap_r[:, 2]\n",
    "out_df['gs_edge_num'] = top_feature_overlap_r[:, 3]\n",
    "out_df.to_csv('yeast_network_v_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf_score                              0.686324\n",
       "linear_score                          0.594146\n",
       "gs_rf_score                           0.657436\n",
       "gs_linear_score                       0.482292\n",
       "rf_with_linear_top_features_score     0.636131\n",
       "linear_with_rf_top_features_score     0.444420\n",
       "rf_rmse                               0.114558\n",
       "linear_rmse                           0.129407\n",
       "gs_rf_rmse                            0.119781\n",
       "gs_linear_rmse                        0.147106\n",
       "rf_with_linear_top_features_rmse      0.117966\n",
       "linear_with_rf_top_features_rmse      0.145690\n",
       "rf_top_feature_num                    6.926783\n",
       "linear_top_feature_num                8.955569\n",
       "test_var                              0.492875\n",
       "test_std                              0.216705\n",
       "rf_with_top_features_score            0.607530\n",
       "linear_with_top_features_score        0.441162\n",
       "rf_with_top_features_rmse             0.123410\n",
       "linear_with_top_features_rmse         0.149660\n",
       "rf_top_features_gs_overlap            1.412390\n",
       "linear_top_features_gs_overlap        2.225490\n",
       "rf_linear_top_features_overlap        1.101377\n",
       "gs_edge_num                          33.782645\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('./yeast_network_v_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(out_df['rf_score'] > out_df['gs_linear_score']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_conf_interval = conf_interval.conf_interval_calc(list(out_df['rf_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_conf_interval[2:] ])+')')\n",
    "linear_conf_interval = conf_interval.conf_interval_calc(list(out_df['linear_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_conf_interval[2:] ])+')')\n",
    "gs_rf_conf_interval = conf_interval.conf_interval_calc(list(out_df['gs_rf_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_rf_conf_interval[2:] ])+')')\n",
    "gs_linear_conf_interval = conf_interval.conf_interval_calc(list(out_df['gs_linear_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_linear_conf_interval[2:] ])+')')\n",
    "rf_with_linear_top_features_conf_interval = conf_interval.conf_interval_calc(list(out_df['rf_with_linear_top_features_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_with_linear_top_features_conf_interval[2:] ])+')')\n",
    "linear_with_rf_top_features_conf_interval = conf_interval.conf_interval_calc(list(out_df['linear_with_rf_top_features_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_with_rf_top_features_conf_interval[2:] ])+')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['rf_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_conf_interval_rmse[2:] ])+')')\n",
    "linear_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['linear_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_conf_interval_rmse[2:] ])+')')\n",
    "gs_rf_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['gs_rf_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_rf_conf_interval_rmse[2:] ])+')')\n",
    "gs_linear_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['gs_linear_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_linear_conf_interval_rmse[2:] ])+')')\n",
    "rf_with_linear_top_features_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['rf_with_linear_top_features_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_with_linear_top_features_conf_interval_rmse[2:] ])+')')\n",
    "linear_with_rf_top_features_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['linear_with_rf_top_features_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_with_rf_top_features_conf_interval_rmse[2:] ])+')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('./yeast_rf_model_network.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "model_combs = list(combinations(out_df.columns[:6], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in model_combs:\n",
    "    t, p = stats.ttest_rel(out_df[a], out_df[b])\n",
    "    c, d, lower, upper = conf_interval.conf_interval_calc(list(out_df[a]-out_df[b]))\n",
    "    if (p > 0.05):\n",
    "        print('{} and {} don\\'t have statistically different performance'.format(a, b))\n",
    "        continue\n",
    "    if (t > 0):\n",
    "        print('{} has statisically better performance than {}, with p-val of {}'.format(a, b, p))\n",
    "        print('confidence interval: ({:.3f}, {:.3f})'.format(lower, upper))\n",
    "    else:\n",
    "        print('{} has statisically better performance than {}, with p-val of {}'.format(b, a, p))\n",
    "        print('confidence interval: ({:.3f}, {:.3f})'.format(lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(10) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.all_linear_comp, range(iter_length)), total=iter_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_r = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_linear_out_df = pd.DataFrame(data=res_r, index=target_gene_list, columns=['linear', 'ridge', 'lasso', 'elastic_net', 'bayesian_ridge', 'quantile', 'quadratic',\n",
    "                                                                             'linear_gs', 'ridge_gs', 'lasso_gs', 'elastic_net_gs', 'bayesian_ridge_gs', 'quantile_gs', 'quadratic_gs'])\n",
    "all_linear_out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_linear_out_df.to_csv('yeast_linear_models.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(target_gene_list), len(tf_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([train_source_df_1, train_source_df_2, train_source_df_3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_split_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(train_source.columns).union(set(train_target.columns), set(test_target.columns), set(test_source.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_target.columns), set(test_target.columns), set(test_source.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
