{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts for regression experiments on mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "import mp_run\n",
    "import conf_interval\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts training/testing data curation \n",
    "\n",
    "df_1 = pd.read_csv('../data/yeast/GSE145936/GSE145936_Sis1-AA_Gene_counts_normalized.txt.gz', sep='\\t', index_col=0, compression='gzip')\n",
    "df_2 = pd.read_csv('../data/yeast/GSE153609/GSE153609_gene_expression_TPM_all_times.csv.gz', index_col=0, compression='gzip')\n",
    "df_3 = pd.read_csv('../data/yeast/GSE168699/GSE168699_RNA_TPM_all_times.csv.gz', index_col=0, compression='gzip')\n",
    "\n",
    "to_drop = df_3.columns[:7]\n",
    "df_3 = df_3.drop(labels=to_drop, axis=1)\n",
    "df_1 = df_1.drop(labels=['gene name'], axis=1)\n",
    "\n",
    "common_genes = set(df_1.index).intersection(set(df_2.index)).intersection(set(df_3.index))\n",
    "common_genes = list(common_genes)\n",
    "# normalized_df_1=(df_1-df_1.min())/(df_1.max()-df_1.min())\n",
    "# normalized_df_2=(df_2-df_2.min())/(df_2.max()-df_2.min())\n",
    "# normalized_df_3=(df_3-df_3.min())/(df_3.max()-df_3.min())\n",
    "normalized_df_1=df_1.apply(stats.zscore, axis=0)\n",
    "normalized_df_2=df_2.apply(stats.zscore, axis=0)\n",
    "normalized_df_3=df_3.apply(stats.zscore, axis=0)\n",
    "# normalized_df_1 = normalized_df_1*100.0\n",
    "# normalized_df_2 = normalized_df_2*100.0\n",
    "# normalized_df_3 = normalized_df_3*100.0\n",
    "normalized_df_1 = normalized_df_1.loc[common_genes]\n",
    "normalized_df_2 = normalized_df_2.loc[common_genes]\n",
    "normalized_df_3 = normalized_df_3.loc[common_genes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_source_target_split(df, time_set, rep_set):\n",
    "    sorted_time_list = sorted(time_set, key=lambda time_str: float(re.search(number_pattern, time_str).group(1)))\n",
    "    print(sorted_time_list)\n",
    "\n",
    "    train_source_time = sorted_time_list[:-2]\n",
    "    train_target_time = sorted_time_list[1:-1]\n",
    "    test_source_time = sorted_time_list[-2:-1]\n",
    "    test_target_time = sorted_time_list[-1:]\n",
    "\n",
    "    train_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_source_time)]\n",
    "    train_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_target_time)]\n",
    "    test_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_source_time)]\n",
    "    test_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_target_time)]\n",
    "    return df[train_source_list], df[train_target_list], df[test_source_list], df[test_target_list]\n",
    "\n",
    "def format_index_and_normalize(df):\n",
    "    normalized_df = df.apply(stats.zscore, axis=0)\n",
    "    selected_index_list = []\n",
    "    new_index_list = []\n",
    "    for index_name in df.index:\n",
    "        names = index_name.split('Name=')[-1]\n",
    "        if ('/' in names):\n",
    "            name_list = names.split('/')[:2]\n",
    "            for name in name_list:\n",
    "                if (name in common_genes):\n",
    "                    selected_index_list.append(index_name)\n",
    "                    new_index_list.append(name)\n",
    "                    continue\n",
    "        elif (names in common_genes):\n",
    "            selected_index_list.append(index_name)\n",
    "            new_index_list.append(names)\n",
    "            continue\n",
    "    len(new_index_list)\n",
    "    new_df = normalized_df.loc[selected_index_list]\n",
    "    new_df.index = new_index_list\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_1 = pd.read_csv('../data/yeast/GSE226769/GSE226769_Meiotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_1 = format_index_and_normalize(df_0_1)\n",
    "df_0_2 = pd.read_csv('../data/yeast/GSE226769/GSE226769_Mitotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_2 = df_0_2.drop(columns=df_0_2.columns[-6:])\n",
    "df_0_2 = format_index_and_normalize(df_0_2)\n",
    "df_0_3 = pd.read_csv('../data/yeast/GSE226769/GSE226769_UME6_T99N_AltAD_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_3 = format_index_and_normalize(df_0_3)\n",
    "df_0_4 = pd.read_csv('../data/yeast/GSE226769/GSE226769_UME6_T99N_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_4 = format_index_and_normalize(df_0_4)\n",
    "\n",
    "common_genes = set(common_genes).intersection(set(df_0_1.index), set(df_0_2.index), set(df_0_3.index), set(df_0_4.index))\n",
    "common_genes = list(common_genes)\n",
    "df_0_1 = df_0_1.loc[common_genes]\n",
    "df_0_2 = df_0_2.loc[common_genes]\n",
    "df_0_3 = df_0_3.loc[common_genes]\n",
    "df_0_4 = df_0_4.loc[common_genes]\n",
    "df_0_1 = df_0_1[~df_0_1.index.duplicated(keep='first')]\n",
    "df_0_2 = df_0_2[~df_0_2.index.duplicated(keep='first')]\n",
    "df_0_3 = df_0_3[~df_0_3.index.duplicated(keep='first')]\n",
    "df_0_4 = df_0_4[~df_0_4.index.duplicated(keep='first')]\n",
    "normalized_df_1 = normalized_df_1.loc[common_genes]\n",
    "normalized_df_2 = normalized_df_2.loc[common_genes]\n",
    "normalized_df_3 = normalized_df_3.loc[common_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_1.columns:\n",
    "    name_segments = name.split('_')\n",
    "    rep_name = ''.join(name_segments[:-1])\n",
    "    time_name = name_segments[-1]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_1.columns = formated_name_list\n",
    "normalized_df = df_0_1.apply(stats.zscore, axis=0)\n",
    "df_split_1 = train_test_source_target_split(normalized_df, time_set, rep_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_2.columns:\n",
    "    pattern = r'(.*)\\(([^()]*)\\)(.*)' \n",
    "    match = re.match(pattern, name)\n",
    "    rep_name = match.group(1) + match.group(3)\n",
    "    rep_set.add(rep_name)\n",
    "    time_name = match.group(2)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "df_0_2.columns = formated_name_list\n",
    "normalized_df = df_0_2.apply(stats.zscore, axis=0)\n",
    "df_split_2 = train_test_source_target_split(normalized_df, time_set, rep_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_3.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_3.columns = formated_name_list\n",
    "normalized_df = df_0_3.apply(stats.zscore, axis=0)\n",
    "df_split_3 = train_test_source_target_split(normalized_df, time_set, rep_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_4.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_4.columns = formated_name_list\n",
    "normalized_df = df_0_4.apply(stats.zscore, axis=0)\n",
    "df_split_4 = train_test_source_target_split(normalized_df, time_set, rep_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_df_1 = normalized_df_1.iloc[:,[3,4,5,9,10,11]]\n",
    "test_df_2 = normalized_df_2.iloc[:,[3,4,5]]\n",
    "test_df_3 = normalized_df_3.iloc[:, -5:]\n",
    "test_exp = pd.concat([test_df_1, test_df_2, test_df_3], axis=1)\n",
    "test_source = test_exp.iloc[:,[0,1,3,4,6,7,9,10,11,12]]\n",
    "test_target = test_exp.iloc[:,[0,1,3,4,6,7,9,10,11,12]]\n",
    "\n",
    "train_source_df_1 = normalized_df_1.iloc[:, [0,1,2,3,5,6,7,8,9]]\n",
    "train_target_df_1 = normalized_df_1.iloc[:, [1,2,3,4,6,7,8,9,10]]\n",
    "train_source_df_2 = normalized_df_2.iloc[:, [0,1,2,3]]\n",
    "train_target_df_2 = normalized_df_2.iloc[:, [1,2,3,4]]\n",
    "\n",
    "train_source_df_3 = normalized_df_3.iloc[:, :-4]\n",
    "train_target_df_3 = normalized_df_3.iloc[:, 1:-3]\n",
    "train_source = pd.concat([train_source_df_1, train_source_df_2, train_source_df_3], axis=1)\n",
    "train_target = pd.concat([train_target_df_1, train_target_df_2, train_target_df_3], axis=1)\n",
    "source_exp = pd.concat([train_source, test_source], axis=1)\n",
    "target_exp = pd.concat([train_target, test_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = pd.concat([train_source, df_split_1[0], df_split_2[0], df_split_3[0], df_split_4[0]], axis=1)\n",
    "train_target = pd.concat([train_target, df_split_1[1], df_split_2[1], df_split_3[1], df_split_4[1]], axis=1)\n",
    "test_source = pd.concat([test_source, df_split_1[2], df_split_2[2], df_split_3[2], df_split_4[2]], axis=1)\n",
    "test_target = pd.concat([test_target, df_split_1[3], df_split_2[3], df_split_3[3], df_split_4[3]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_df_1 = pd.read_csv('../data/yeast/GSE145936/normalized/train_source.csv.gz', compression='gzip', index_col=0)\n",
    "train_target_df_1 = pd.read_csv('../data/yeast/GSE145936/normalized/train_target.csv.gz', compression='gzip', index_col=0)\n",
    "test_source_df_1 = pd.read_csv('../data/yeast/GSE145936/normalized/test_source.csv.gz', compression='gzip', index_col=0)\n",
    "test_target_df_1 = pd.read_csv('../data/yeast/GSE145936/normalized/test_target.csv.gz', compression='gzip', index_col=0)\n",
    "\n",
    "train_source_df_2 = pd.read_csv('../data/yeast/GSE153609/normalized/train_source.csv.gz', compression='gzip', index_col=0)\n",
    "train_target_df_2 = pd.read_csv('../data/yeast/GSE153609/normalized/train_target.csv.gz', compression='gzip', index_col=0)\n",
    "test_source_df_2 = pd.read_csv('../data/yeast/GSE153609/normalized/test_source.csv.gz', compression='gzip', index_col=0)\n",
    "test_target_df_2 = pd.read_csv('../data/yeast/GSE153609/normalized/test_target.csv.gz', compression='gzip', index_col=0)\n",
    "\n",
    "train_source_df_3 = pd.read_csv('../data/yeast/GSE168699/normalized/train_source.csv.gz', compression='gzip', index_col=0)\n",
    "train_target_df_3 = pd.read_csv('../data/yeast/GSE168699/normalized/train_target.csv.gz', compression='gzip', index_col=0)\n",
    "test_source_df_3 = pd.read_csv('../data/yeast/GSE168699/normalized/test_source.csv.gz', compression='gzip', index_col=0)\n",
    "test_target_df_3 = pd.read_csv('../data/yeast/GSE168699/normalized/test_target.csv.gz', compression='gzip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_4_1 = pd.read_csv('../data/yeast/GSE226769/normalized/train_source_1.csv.gz', compression='gzip', index_col=0)\n",
    "train_target_4_1 = pd.read_csv('../data/yeast/GSE226769/normalized/train_target_1.csv.gz', compression='gzip', index_col=0)\n",
    "test_source_4_1 = pd.read_csv('../data/yeast/GSE226769/normalized/test_source_1.csv.gz', compression='gzip', index_col=0)\n",
    "test_target_4_1 = pd.read_csv('../data/yeast/GSE226769/normalized/test_target_1.csv.gz', compression='gzip', index_col=0)\n",
    "\n",
    "train_source_4_2 = pd.read_csv('../data/yeast/GSE226769/normalized/train_source_2.csv.gz', compression='gzip', index_col=0)\n",
    "train_target_4_2 = pd.read_csv('../data/yeast/GSE226769/normalized/train_target_2.csv.gz', compression='gzip', index_col=0)\n",
    "test_source_4_2 = pd.read_csv('../data/yeast/GSE226769/normalized/test_source_2.csv.gz', compression='gzip', index_col=0)\n",
    "test_target_4_2 = pd.read_csv('../data/yeast/GSE226769/normalized/test_target_2.csv.gz', compression='gzip', index_col=0)\n",
    "\n",
    "train_source_4_3 = pd.read_csv('../data/yeast/GSE226769/normalized/train_source_3.csv.gz', compression='gzip', index_col=0)\n",
    "train_target_4_3 = pd.read_csv('../data/yeast/GSE226769/normalized/train_target_3.csv.gz', compression='gzip', index_col=0)\n",
    "test_source_4_3 = pd.read_csv('../data/yeast/GSE226769/normalized/test_source_3.csv.gz', compression='gzip', index_col=0)\n",
    "test_target_4_3 = pd.read_csv('../data/yeast/GSE226769/normalized/test_target_3.csv.gz', compression='gzip', index_col=0)\n",
    "\n",
    "train_source_4_4 = pd.read_csv('../data/yeast/GSE226769/normalized/train_source_4.csv.gz', compression='gzip', index_col=0)\n",
    "train_target_4_4 = pd.read_csv('../data/yeast/GSE226769/normalized/train_target_4.csv.gz', compression='gzip', index_col=0)\n",
    "test_source_4_4 = pd.read_csv('../data/yeast/GSE226769/normalized/test_source_4.csv.gz', compression='gzip', index_col=0)\n",
    "test_target_4_4 = pd.read_csv('../data/yeast/GSE226769/normalized/test_target_4.csv.gz', compression='gzip', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = pd.concat([train_source_df_1, train_source_df_2, train_source_df_3, train_source_4_1, train_source_4_2, train_source_4_3, train_source_4_4], axis=1)\n",
    "train_target = pd.concat([train_target_df_1, train_target_df_2, train_target_df_3, train_target_4_1, train_target_4_2, train_target_4_3, train_target_4_4], axis=1)\n",
    "test_source = pd.concat([test_source_df_1, test_source_df_2, test_source_df_3, test_source_4_1, test_source_4_2, test_source_4_3, test_source_4_4], axis=1)\n",
    "test_target = pd.concat([test_target_df_1, test_target_df_2, test_target_df_3, test_target_4_1, test_target_4_2, test_target_4_3, test_target_4_4], axis=1)\n",
    "\n",
    "common_genes = list(train_source.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of TFs used:\n",
      "495\n"
     ]
    }
   ],
   "source": [
    "# get network data, training features\n",
    "tf_set = set()\n",
    "tf_list_df = pd.read_csv('../data/yeast/yeast_tf_list.tsv.gz', sep='\\t', compression='gzip', index_col=0)\n",
    "for name in tf_list_df['Gene Names']:\n",
    "    name_splits = name.split(' ')\n",
    "    for i in name_splits:\n",
    "        if i.upper() in train_source.index:\n",
    "            tf_set.add(i.upper())\n",
    "\n",
    "network_df = pd.read_csv('../data/yeast/yeat_network.csv', index_col=0)\n",
    "target_gene_list = []\n",
    "for i, row in network_df.iterrows():\n",
    "    tf_list = row.tf_list\n",
    "    if pd.isnull(tf_list): \n",
    "        continue\n",
    "    tf_list = tf_list.split('; ')\n",
    "    tf_set = tf_set.union(set(tf_list))\n",
    "    target_gene_list.append(i)\n",
    "\n",
    "print('Number of TFs used:')\n",
    "print(len(tf_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get network data, training features\n",
    "# network_df = pd.read_csv('../data/yeast/yeat_network.csv', index_col=0)\n",
    "# tf_set = set()\n",
    "# target_gene_list = []\n",
    "# for i, row in network_df.iterrows():\n",
    "#     tf_list = row.tf_list\n",
    "#     if pd.isnull(tf_list): \n",
    "#         continue\n",
    "#     tf_list = tf_list.split('; ')\n",
    "#     tf_set = tf_set.union(set(tf_list))\n",
    "#     target_gene_list.append(i)\n",
    "\n",
    "# print(len(tf_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_exp = pd.concat([train_target, test_target], axis=1)\n",
    "source_exp = pd.concat([train_source, test_source], axis=1)\n",
    "target_gene_list = list(set(target_gene_list).intersection(set(common_genes)))\n",
    "# filterout NaN target:\n",
    "target_gene_list = list(target_exp.loc[target_gene_list][target_exp.loc[target_gene_list].isnull().any(axis=1)==False].index)\n",
    "tf_list = list(tf_set.intersection(set(common_genes)))\n",
    "tf_list_df = pd.read_csv('../output/network_model/yeast_tf.csv', names=['tf'], index_col=0)\n",
    "tf_list = list(tf_list_df.index)\n",
    "\n",
    "X = source_exp.loc[tf_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS edge count:\n",
      "162100\n",
      "Number of TFs in GS:\n",
      "205\n",
      "Number of target genes in GS:\n",
      "4794\n"
     ]
    }
   ],
   "source": [
    "# GS stats\n",
    "edge_count = 0\n",
    "gs_tf_set = set()\n",
    "gs_target_set = set()\n",
    "for i, row in network_df.iterrows():\n",
    "    if i in target_gene_list:\n",
    "        cur_tf_list = row.tf_list\n",
    "        gs_target_set.add(i)\n",
    "        if pd.isnull(cur_tf_list): \n",
    "            continue\n",
    "        cur_tf_list = cur_tf_list.split('; ')\n",
    "        for cur_tf in cur_tf_list:\n",
    "            if cur_tf in tf_list:\n",
    "                gs_tf_set.add(cur_tf)\n",
    "                edge_count += 1\n",
    "print('GS edge count:')\n",
    "print(edge_count)\n",
    "print('Number of TFs in GS:')\n",
    "print(len(gs_tf_set))\n",
    "print('Number of target genes in GS:')\n",
    "print(len(gs_target_set))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for high variance targets\n",
    "\n",
    "new_test_target = test_target.loc[target_gene_list]\n",
    "new_test_target = new_test_target.loc[new_test_target.std(axis=1) > 0.5]\n",
    "target_gene_list = new_test_target.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_calc = mp_run.MpCalc(target_gene_list, target_exp, X, network_df, train_source.loc[tf_list], train_target, test_source.loc[tf_list], test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [01:02<00:00,  6.15it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.full_comp_new, range(iter_length)), total=iter_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(r)\n",
    "out_df = pd.DataFrame(index=target_gene_list)\n",
    "out_df['rf_score'] = r[:, 0]\n",
    "out_df['linear_score'] = r[:, 1]\n",
    "out_df['gs_rf_score'] = r[:, 2]\n",
    "out_df['gs_linear_score'] = r[:, 3]\n",
    "out_df['rf_with_linear_top_features_score'] = r[:, 4]\n",
    "out_df['linear_with_rf_top_features_score'] = r[:, 5]\n",
    "out_df['rf_rmse'] = r[:, 6]\n",
    "out_df['linear_rmse'] = r[:, 7]\n",
    "out_df['gs_rf_rmse'] = r[:, 8]\n",
    "out_df['gs_linear_rmse'] = r[:, 9]\n",
    "out_df['rf_with_linear_top_features_rmse'] = r[:, 10]\n",
    "out_df['linear_with_rf_top_features_rmse'] = r[:, 11]\n",
    "out_df['rf_with_top_features_score'] = r[:, 12]\n",
    "out_df['linear_with_top_features_score'] = r[:, 13]\n",
    "out_df['rf_with_top_features_rmse'] = r[:, 14]\n",
    "out_df['linear_with_top_features_rmse'] = r[:, 15]\n",
    "out_df['rf_top_feature_num'] = r[:, 16]\n",
    "out_df['linear_top_feature_num'] = r[:, 17]\n",
    "out_df['rf_top_features_gs_overlap'] = r[:, 18]\n",
    "out_df['linear_top_features_gs_overlap'] = r[:, 19]\n",
    "out_df['rf_linear_top_features_overlap'] = r[:, 20]\n",
    "out_df['gs_edge_num'] = r[:, 21]\n",
    "out_df['test_var'] = r[:, 22]\n",
    "out_df['test_std'] = r[:, 23]\n",
    "out_df['pca_rf_score'] = r[:, 24]\n",
    "out_df['pca_rf_rmse'] = r[:, 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_list_df = pd.DataFrame(index=tf_list)\n",
    "tf_list_df.to_csv('../output/network_model/yeast_tf.csv', header=False)\n",
    "out_df.to_csv('../output/network_model/yeast_all_tf_high_var_target_new.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:10<00:00, 36.69it/s]\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.read_csv('../output/network_model/yeast_all_tf_high_var_target_new.csv.gz', index_col=0, compression='gzip')\n",
    "iter_length = len(target_gene_list)\n",
    "new_out_df = pd.DataFrame(index=target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.rf_top_tf_same_count_as_gs, range(iter_length)), total=iter_length))\n",
    "efron_r = np.array(r)\n",
    "new_out_df['rf_top_tf_same_count_as_gs_score'] = efron_r[:, 0]\n",
    "new_out_df['rf_top_tf_same_count_as_gs_rmse'] = efron_r[:, 1]\n",
    "new_out_df = new_out_df.loc[out_df.index]\n",
    "out_df['rf_top_tf_same_count_as_gs_score'] = new_out_df['rf_top_tf_same_count_as_gs_score']\n",
    "out_df['rf_top_tf_same_count_as_gs_rmse'] = new_out_df['rf_top_tf_same_count_as_gs_rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('../output/network_model/yeast_all_tf_high_var_target_new.csv.gz', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [05:36<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.read_csv('../output/network_model/yeast_all_tf_high_var_target_new.csv.gz', index_col=0, compression='gzip')\n",
    "iter_length = len(target_gene_list)\n",
    "new_out_df = pd.DataFrame(index=target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.efron_process_rf_training, range(iter_length)), total=iter_length))\n",
    "efron_r = np.array(r)\n",
    "new_out_df['rf_efron_feature_num'] = efron_r[:, 0].astype('float64')\n",
    "new_out_df['rf_efron_complementary_feature_num_list'] = efron_r[:, 1]\n",
    "new_out_df['rf_efron_rmse'] = efron_r[:, 2].astype('float64')\n",
    "new_out_df['rf_efron_complementary_rmse_list'] = efron_r[:, 3]\n",
    "new_out_df['rf_efron_features'] = efron_r[:, 4]\n",
    "new_out_df['rf_efron_complementary_features_list'] = efron_r[:, 5]\n",
    "new_out_df['rf_efron_ensemble_rmse'] = efron_r[:, 6]\n",
    "new_out_df = new_out_df.loc[out_df.index]\n",
    "out_df['rf_efron_feature_num'] = new_out_df['rf_efron_feature_num']\n",
    "out_df['rf_efron_complementary_feature_num_list'] = new_out_df['rf_efron_complementary_feature_num_list']\n",
    "out_df['rf_efron_rmse'] = new_out_df['rf_efron_rmse']\n",
    "out_df['rf_efron_complementary_rmse_list'] = new_out_df['rf_efron_complementary_rmse_list']\n",
    "out_df['rf_efron_features'] = new_out_df['rf_efron_features']\n",
    "out_df['rf_efron_complementary_features_list'] = new_out_df['rf_efron_complementary_features_list']\n",
    "out_df['rf_efron_ensemble_rmse'] = new_out_df['rf_efron_ensemble_rmse']\n",
    "\n",
    "out_df.to_csv('../output/network_model/yeast_all_tf_high_var_target_efron_train.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_list_df = pd.read_csv('../output/network_model/yeast_tf.csv', names=['tf'], index_col=0)\n",
    "out_df = pd.read_csv('../output/network_model/yeast_all_tf_high_var_target_efron_train.csv.gz', index_col=0, compression='gzip')\n",
    "available_tfs = set(X.index)\n",
    "rf_efron_overlap_count = []\n",
    "for target_gene in out_df.index:\n",
    "    gs_tf_list = network_df.loc[target_gene].tf_list\n",
    "    gs_tf_set = set(gs_tf_list.split('; '))\n",
    "    gs_tf_set = available_tfs.intersection(gs_tf_set)\n",
    "    if target_gene in gs_tf_set: gs_tf_set.remove(target_gene)\n",
    "    efron_tf_list = out_df.loc[target_gene]['rf_efron_features']\n",
    "    efron_tf_list = efron_tf_list.split('; ')\n",
    "    efron_tf_list = [int(i) for i in efron_tf_list]\n",
    "    efron_tf_list = tf_list_df.iloc[efron_tf_list].index\n",
    "    efron_tf_set = set(efron_tf_list)\n",
    "    rf_efron_overlap_count.append(len(efron_tf_set.intersection(gs_tf_set)))\n",
    "out_df['rf_efron_overlap_count'] = rf_efron_overlap_count\n",
    "out_df.to_csv('../output/network_model/yeast_all_tf_high_var_target_efron_train.csv.gz', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [00:12<00:00, 31.37it/s]\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.read_csv('../output/network_model/yeast_all_tf_high_var_target_efron_train.csv.gz', index_col=0, compression='gzip')\n",
    "iter_length = len(target_gene_list)\n",
    "new_out_df = pd.DataFrame(index=target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.rf_top_10, range(iter_length)), total=iter_length))\n",
    "top10_r = np.array(r)\n",
    "new_out_df['rf_top10_score'] = top10_r[:, 0].astype('float64')\n",
    "new_out_df['rf_top10_rmse'] = top10_r[:, 1].astype('float64')\n",
    "new_out_df = new_out_df.loc[out_df.index]\n",
    "out_df['rf_top10_score'] = new_out_df['rf_top10_score']\n",
    "out_df['rf_top10_rmse'] = new_out_df['rf_top10_rmse']\n",
    "out_df.to_csv('../output/network_model/yeast_all_tf_high_var_target_efron_train.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf_score                              0.609127\n",
       "linear_score                          0.147335\n",
       "gs_rf_score                           0.579119\n",
       "gs_linear_score                       0.456120\n",
       "rf_with_linear_top_features_score     0.620660\n",
       "linear_with_rf_top_features_score     0.442544\n",
       "rf_rmse                               0.876901\n",
       "linear_rmse                           1.203858\n",
       "gs_rf_rmse                            0.922259\n",
       "gs_linear_rmse                        1.091308\n",
       "rf_with_linear_top_features_rmse      0.865159\n",
       "linear_with_rf_top_features_rmse      0.991998\n",
       "rf_with_top_features_score            0.605025\n",
       "linear_with_top_features_score        0.020866\n",
       "rf_with_top_features_rmse             0.879590\n",
       "linear_with_top_features_rmse         1.254643\n",
       "rf_top_feature_num                   20.000000\n",
       "linear_top_feature_num               20.000000\n",
       "rf_top_features_gs_overlap            2.192208\n",
       "linear_top_features_gs_overlap        1.724675\n",
       "rf_linear_top_features_overlap        2.880519\n",
       "gs_edge_num                          52.493506\n",
       "test_var                              6.061592\n",
       "test_std                              1.589845\n",
       "pca_rf_score                          0.360476\n",
       "pca_rf_rmse                           1.151172\n",
       "rf_top_tf_same_count_as_gs_score      0.621095\n",
       "rf_top_tf_same_count_as_gs_rmse       0.859284\n",
       "rf_efron_feature_num                  6.989610\n",
       "rf_efron_rmse                         0.965153\n",
       "rf_efron_ensemble_rmse                0.910661\n",
       "rf_efron_overlap_count                0.753247\n",
       "rf_top10_score                        0.577545\n",
       "rf_top10_rmse                         0.902223\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
