{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "import mp_run\n",
    "import conf_interval\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts training/testing data curation \n",
    "\n",
    "df_1 = pd.read_csv('../data/yeast/GSE145936_Sis1-AA_Gene_counts_normalized.txt', sep='\\t', index_col=0)\n",
    "df_2 = pd.read_csv('../data/yeast/GSE153609_gene_expression_TPM_all_times.csv', index_col=0)\n",
    "df_3 = pd.read_csv('../data/yeast/GSE168699_RNA_TPM_all_times.csv', index_col=0)\n",
    "\n",
    "to_drop = df_3.columns[:7]\n",
    "df_3 = df_3.drop(labels=to_drop, axis=1)\n",
    "df_1 = df_1.drop(labels=['gene name'], axis=1)\n",
    "\n",
    "common_genes = set(df_1.index).intersection(set(df_2.index)).intersection(set(df_3.index))\n",
    "common_genes = list(common_genes)\n",
    "# normalized_df_1=(df_1-df_1.min())/(df_1.max()-df_1.min())\n",
    "# normalized_df_2=(df_2-df_2.min())/(df_2.max()-df_2.min())\n",
    "# normalized_df_3=(df_3-df_3.min())/(df_3.max()-df_3.min())\n",
    "normalized_df_1=df_1.apply(stats.zscore, axis=0)\n",
    "normalized_df_2=df_2.apply(stats.zscore, axis=0)\n",
    "normalized_df_3=df_3.apply(stats.zscore, axis=0)\n",
    "# normalized_df_1 = normalized_df_1*100.0\n",
    "# normalized_df_2 = normalized_df_2*100.0\n",
    "# normalized_df_3 = normalized_df_3*100.0\n",
    "normalized_df_1 = normalized_df_1.loc[common_genes]\n",
    "normalized_df_2 = normalized_df_2.loc[common_genes]\n",
    "normalized_df_3 = normalized_df_3.loc[common_genes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_source_target_split(df, time_set, rep_set):\n",
    "    sorted_time_list = sorted(time_set, key=lambda time_str: float(re.search(number_pattern, time_str).group(1)))\n",
    "    print(sorted_time_list)\n",
    "\n",
    "    train_source_time = sorted_time_list[:-2]\n",
    "    train_target_time = sorted_time_list[1:-1]\n",
    "    test_source_time = sorted_time_list[-2:-1]\n",
    "    test_target_time = sorted_time_list[-1:]\n",
    "\n",
    "    train_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_source_time)]\n",
    "    train_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_target_time)]\n",
    "    test_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_source_time)]\n",
    "    test_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_target_time)]\n",
    "    return df[train_source_list], df[train_target_list], df[test_source_list], df[test_target_list]\n",
    "\n",
    "def format_index_and_normalize(df):\n",
    "    normalized_df = df.apply(stats.zscore, axis=0)\n",
    "    selected_index_list = []\n",
    "    new_index_list = []\n",
    "    for index_name in df.index:\n",
    "        names = index_name.split('Name=')[-1]\n",
    "        if ('/' in names):\n",
    "            name_list = names.split('/')[:2]\n",
    "            for name in name_list:\n",
    "                if (name in common_genes):\n",
    "                    selected_index_list.append(index_name)\n",
    "                    new_index_list.append(name)\n",
    "                    continue\n",
    "        elif (names in common_genes):\n",
    "            selected_index_list.append(index_name)\n",
    "            new_index_list.append(names)\n",
    "            continue\n",
    "    len(new_index_list)\n",
    "    new_df = normalized_df.loc[selected_index_list]\n",
    "    new_df.index = new_index_list\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_1 = pd.read_csv('../data/yeast/GSE226769/GSE226769_Meiotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_1 = format_index_and_normalize(df_0_1)\n",
    "df_0_2 = pd.read_csv('../data/yeast/GSE226769/GSE226769_Mitotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_2 = df_0_2.drop(columns=df_0_2.columns[-6:])\n",
    "df_0_2 = format_index_and_normalize(df_0_2)\n",
    "df_0_3 = pd.read_csv('../data/yeast/GSE226769/GSE226769_UME6_T99N_AltAD_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_3 = format_index_and_normalize(df_0_3)\n",
    "df_0_4 = pd.read_csv('../data/yeast/GSE226769/GSE226769_UME6_T99N_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_0_4 = format_index_and_normalize(df_0_4)\n",
    "\n",
    "common_genes = set(common_genes).intersection(set(df_0_1.index), set(df_0_2.index), set(df_0_3.index), set(df_0_4.index))\n",
    "common_genes = list(common_genes)\n",
    "df_0_1 = df_0_1.loc[common_genes]\n",
    "df_0_2 = df_0_2.loc[common_genes]\n",
    "df_0_3 = df_0_3.loc[common_genes]\n",
    "df_0_4 = df_0_4.loc[common_genes]\n",
    "df_0_1 = df_0_1[~df_0_1.index.duplicated(keep='first')]\n",
    "df_0_2 = df_0_2[~df_0_2.index.duplicated(keep='first')]\n",
    "df_0_3 = df_0_3[~df_0_3.index.duplicated(keep='first')]\n",
    "df_0_4 = df_0_4[~df_0_4.index.duplicated(keep='first')]\n",
    "normalized_df_1 = normalized_df_1.loc[common_genes]\n",
    "normalized_df_2 = normalized_df_2.loc[common_genes]\n",
    "normalized_df_3 = normalized_df_3.loc[common_genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "['0.5HR', '2HR', '2.5HR', '3HR', '4.5HR', '6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_1.columns:\n",
    "    name_segments = name.split('_')\n",
    "    rep_name = ''.join(name_segments[:-1])\n",
    "    time_name = name_segments[-1]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_1.columns = formated_name_list\n",
    "normalized_df = df_0_1.apply(stats.zscore, axis=0)\n",
    "df_split_1 = train_test_source_target_split(normalized_df, time_set, rep_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-30min', '0min', '15min', '30min', '60min', '120min']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_2.columns:\n",
    "    pattern = r'(.*)\\(([^()]*)\\)(.*)' \n",
    "    match = re.match(pattern, name)\n",
    "    rep_name = match.group(1) + match.group(3)\n",
    "    rep_set.add(rep_name)\n",
    "    time_name = match.group(2)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "df_0_2.columns = formated_name_list\n",
    "normalized_df = df_0_2.apply(stats.zscore, axis=0)\n",
    "df_split_2 = train_test_source_target_split(normalized_df, time_set, rep_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 4\n",
      "['0HR', '2HR', '4HR', '6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_3.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_3.columns = formated_name_list\n",
    "normalized_df = df_0_3.apply(stats.zscore, axis=0)\n",
    "df_split_3 = train_test_source_target_split(normalized_df, time_set, rep_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 4\n",
      "[' 0HR', ' 2HR', ' 4HR', ' 6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_0_4.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_0_4.columns = formated_name_list\n",
    "normalized_df = df_0_4.apply(stats.zscore, axis=0)\n",
    "df_split_4 = train_test_source_target_split(normalized_df, time_set, rep_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_df_1 = normalized_df_1.iloc[:,[3,4,5,9,10,11]]\n",
    "test_df_2 = normalized_df_2.iloc[:,[3,4,5]]\n",
    "test_df_3 = normalized_df_3.iloc[:, -5:]\n",
    "test_exp = pd.concat([test_df_1, test_df_2, test_df_3], axis=1)\n",
    "test_source = test_exp.iloc[:,[0,1,3,4,6,7,9,10,11,12]]\n",
    "test_target = test_exp.iloc[:,[0,1,3,4,6,7,9,10,11,12]]\n",
    "\n",
    "train_source_df_1 = normalized_df_1.iloc[:, [0,1,2,3,5,6,7,8,9]]\n",
    "train_target_df_1 = normalized_df_1.iloc[:, [1,2,3,4,6,7,8,9,10]]\n",
    "train_source_df_2 = normalized_df_2.iloc[:, [0,1,2,3]]\n",
    "train_target_df_2 = normalized_df_2.iloc[:, [1,2,3,4]]\n",
    "\n",
    "train_source_df_3 = normalized_df_3.iloc[:, :-4]\n",
    "train_target_df_3 = normalized_df_3.iloc[:, 1:-3]\n",
    "train_source = pd.concat([train_source_df_1, train_source_df_2, train_source_df_3], axis=1)\n",
    "train_target = pd.concat([train_target_df_1, train_target_df_2, train_target_df_3], axis=1)\n",
    "source_exp = pd.concat([train_source, test_source], axis=1)\n",
    "target_exp = pd.concat([train_target, test_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source = pd.concat([train_source, df_split_1[0], df_split_2[0], df_split_3[0], df_split_4[0]], axis=1)\n",
    "train_target = pd.concat([train_target, df_split_1[1], df_split_2[1], df_split_3[1], df_split_4[1]], axis=1)\n",
    "test_source = pd.concat([test_source, df_split_1[2], df_split_2[2], df_split_3[2], df_split_4[2]], axis=1)\n",
    "test_target = pd.concat([test_target, df_split_1[3], df_split_2[3], df_split_3[3], df_split_4[3]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495\n"
     ]
    }
   ],
   "source": [
    "# get network data, training features\n",
    "tf_set = set()\n",
    "tf_list_df = pd.read_csv('../data/yeast_tf_list.tsv.gz', sep='\\t', compression='gzip', index_col=0)\n",
    "for name in tf_list_df['Gene Names']:\n",
    "    name_splits = name.split(' ')\n",
    "    for i in name_splits:\n",
    "        if i.upper() in train_source.index:\n",
    "            tf_set.add(i.upper())\n",
    "\n",
    "network_df = pd.read_csv('./yeat_network.csv', index_col=0)\n",
    "target_gene_list = []\n",
    "for i, row in network_df.iterrows():\n",
    "    tf_list = row.tf_list\n",
    "    if pd.isnull(tf_list): \n",
    "        continue\n",
    "    tf_list = tf_list.split('; ')\n",
    "    tf_set = tf_set.union(set(tf_list))\n",
    "    target_gene_list.append(i)\n",
    "print(len(tf_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213\n"
     ]
    }
   ],
   "source": [
    "# get network data, training features\n",
    "network_df = pd.read_csv('./yeat_network.csv', index_col=0)\n",
    "tf_set = set()\n",
    "target_gene_list = []\n",
    "for i, row in network_df.iterrows():\n",
    "    tf_list = row.tf_list\n",
    "    if pd.isnull(tf_list): \n",
    "        continue\n",
    "    tf_list = tf_list.split('; ')\n",
    "    tf_set = tf_set.union(set(tf_list))\n",
    "    target_gene_list.append(i)\n",
    "\n",
    "print(len(tf_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_gene_list = list(set(target_gene_list).intersection(set(common_genes)))\n",
    "# filterout NaN target:\n",
    "target_gene_list = list(target_exp.loc[target_gene_list][target_exp.loc[target_gene_list].isnull().any(axis=1)==False].index)\n",
    "tf_list = list(tf_set.intersection(set(common_genes)))\n",
    "\n",
    "X = source_exp.loc[tf_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_var_target_genes = set(normalized_df_1.var(axis=1).sort_values(ascending=False).head(500).index).intersection(\n",
    "    set(normalized_df_2.var(axis=1).sort_values(ascending=False).head(500).index)).intersection(\n",
    "    set(normalized_df_3.var(axis=1).sort_values(ascending=False).head(500).index))\n",
    "high_var_target_genes = high_var_target_genes.difference(set(tf_list))\n",
    "\n",
    "high_var_target_genes = list(high_var_target_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_target = test_target.loc[target_gene_list]\n",
    "new_test_target = new_test_target.loc[new_test_target.std(axis=1) > 0.5]\n",
    "target_gene_list = new_test_target.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_calc = mp_run.MpCalc(target_gene_list, target_exp, X, network_df, train_source.loc[tf_list], train_target, test_source.loc[tf_list], test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [00:40<00:00,  9.28it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.full_comp_new, range(iter_length)), total=iter_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.array(r)\n",
    "out_df = pd.DataFrame(index=target_gene_list)\n",
    "out_df['rf_score'] = r[:, 0]\n",
    "out_df['linear_score'] = r[:, 1]\n",
    "out_df['gs_rf_score'] = r[:, 2]\n",
    "out_df['gs_linear_score'] = r[:, 3]\n",
    "out_df['rf_with_linear_top_features_score'] = r[:, 4]\n",
    "out_df['linear_with_rf_top_features_score'] = r[:, 5]\n",
    "out_df['rf_rmse'] = r[:, 6]\n",
    "out_df['linear_rmse'] = r[:, 7]\n",
    "out_df['gs_rf_rmse'] = r[:, 8]\n",
    "out_df['gs_linear_rmse'] = r[:, 9]\n",
    "out_df['rf_with_linear_top_features_rmse'] = r[:, 10]\n",
    "out_df['linear_with_rf_top_features_rmse'] = r[:, 11]\n",
    "out_df['rf_with_top_features_score'] = r[:, 12]\n",
    "out_df['linear_with_top_features_score'] = r[:, 13]\n",
    "out_df['rf_with_top_features_rmse'] = r[:, 14]\n",
    "out_df['linear_with_top_features_rmse'] = r[:, 15]\n",
    "out_df['rf_top_feature_num'] = r[:, 16]\n",
    "out_df['linear_top_feature_num'] = r[:, 17]\n",
    "out_df['rf_top_features_gs_overlap'] = r[:, 18]\n",
    "out_df['linear_top_features_gs_overlap'] = r[:, 19]\n",
    "out_df['rf_linear_top_features_overlap'] = r[:, 20]\n",
    "out_df['gs_edge_num'] = r[:, 21]\n",
    "out_df['test_var'] = r[:, 22]\n",
    "out_df['test_std'] = r[:, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('../output/network_model/yeast_all_tf_high_var_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = out_df[out_df['test_std'] > 0.5]\n",
    "filtered_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf_score                              0.655937\n",
       "linear_score                          0.129465\n",
       "gs_rf_score                           0.633867\n",
       "gs_linear_score                       0.495720\n",
       "rf_with_linear_top_features_score     0.635252\n",
       "linear_with_rf_top_features_score     0.457644\n",
       "rf_rmse                               0.799430\n",
       "linear_rmse                           1.205856\n",
       "gs_rf_rmse                            0.844297\n",
       "gs_linear_rmse                        1.041394\n",
       "rf_with_linear_top_features_rmse      0.811669\n",
       "linear_with_rf_top_features_rmse      1.023141\n",
       "rf_with_top_features_score            0.606001\n",
       "linear_with_top_features_score       -0.300895\n",
       "rf_with_top_features_rmse             0.856001\n",
       "linear_with_top_features_rmse         1.295084\n",
       "rf_top_feature_num                    7.443272\n",
       "linear_top_feature_num               10.464380\n",
       "rf_top_features_gs_overlap            0.701847\n",
       "linear_top_features_gs_overlap        1.166227\n",
       "rf_linear_top_features_overlap        0.741425\n",
       "gs_edge_num                          52.667546\n",
       "test_var                              6.038460\n",
       "test_std                              1.585118\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.read_csv('../output/network_model/yeast_all_tf_high_var_target.csv', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [00:29<00:00, 12.73it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.efron_process_rf, range(iter_length)), total=iter_length))\n",
    "efron_r = np.array(r)\n",
    "out_df['rf_efron_feature_num'] = efron_r[:, 0]\n",
    "out_df['rf_efron_rmse'] = efron_r[:, 1]\n",
    "out_df['rf_efron_complementary_rmse'] = efron_r[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [00:38<00:00,  9.73it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.efron_process_linear, range(iter_length)), total=iter_length))\n",
    "efron_r = np.array(r)\n",
    "out_df['linear_efron_feature_num'] = efron_r[:, 0]\n",
    "out_df['linear_efron_rmse'] = efron_r[:, 1]\n",
    "out_df['linear_efron_complementary_rmse'] = efron_r[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 379/379 [01:51<00:00,  3.39it/s]\n"
     ]
    }
   ],
   "source": [
    "iter_length = len(target_gene_list)\n",
    "with Pool(cpu_count()) as p:\n",
    "    r = list(tqdm(p.imap(mp_calc.efron_process_90th_rf, range(iter_length)), total=iter_length))\n",
    "efron_r = np.array(r)\n",
    "out_df['rf_efron_feature_num_90th'] = efron_r[:, 0]\n",
    "out_df['rf_efron_rmse_90th'] = efron_r[:, 1]\n",
    "out_df['rf_efron_complementary_rmse_90th'] = efron_r[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('../output/network_model/yeast_all_tf_high_var_target.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_conf_interval = conf_interval.conf_interval_calc(list(out_df['rf_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_conf_interval[2:] ])+')')\n",
    "linear_conf_interval = conf_interval.conf_interval_calc(list(out_df['linear_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_conf_interval[2:] ])+')')\n",
    "gs_rf_conf_interval = conf_interval.conf_interval_calc(list(out_df['gs_rf_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_rf_conf_interval[2:] ])+')')\n",
    "gs_linear_conf_interval = conf_interval.conf_interval_calc(list(out_df['gs_linear_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_linear_conf_interval[2:] ])+')')\n",
    "rf_with_linear_top_features_conf_interval = conf_interval.conf_interval_calc(list(out_df['rf_with_linear_top_features_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_with_linear_top_features_conf_interval[2:] ])+')')\n",
    "linear_with_rf_top_features_conf_interval = conf_interval.conf_interval_calc(list(out_df['linear_with_rf_top_features_score'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_with_rf_top_features_conf_interval[2:] ])+')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['rf_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_conf_interval_rmse[2:] ])+')')\n",
    "linear_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['linear_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_conf_interval_rmse[2:] ])+')')\n",
    "gs_rf_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['gs_rf_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_rf_conf_interval_rmse[2:] ])+')')\n",
    "gs_linear_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['gs_linear_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in gs_linear_conf_interval_rmse[2:] ])+')')\n",
    "rf_with_linear_top_features_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['rf_with_linear_top_features_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in rf_with_linear_top_features_conf_interval_rmse[2:] ])+')')\n",
    "linear_with_rf_top_features_conf_interval_rmse = conf_interval.conf_interval_calc(list(out_df['linear_with_rf_top_features_rmse'].values))\n",
    "print('('+', '.join([ '%.3f' % elem for elem in linear_with_rf_top_features_conf_interval_rmse[2:] ])+')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "model_combs = list(combinations(out_df.columns[:6], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in model_combs:\n",
    "    t, p = stats.ttest_rel(out_df[a], out_df[b])\n",
    "    c, d, lower, upper = conf_interval.conf_interval_calc(list(out_df[a]-out_df[b]))\n",
    "    if (p > 0.05):\n",
    "        print('{} and {} don\\'t have statistically different performance'.format(a, b))\n",
    "        continue\n",
    "    if (t > 0):\n",
    "        print('{} has statisically better performance than {}, with p-val of {}'.format(a, b, p))\n",
    "        print('confidence interval: ({:.3f}, {:.3f})'.format(lower, upper))\n",
    "    else:\n",
    "        print('{} has statisically better performance than {}, with p-val of {}'.format(b, a, p))\n",
    "        print('confidence interval: ({:.3f}, {:.3f})'.format(lower, upper))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
