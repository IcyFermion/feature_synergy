{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from multiprocessing import shared_memory\n",
    "from multiprocessing.dummy import Pool\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import multiprocessing as mp\n",
    "from itertools import chain, combinations\n",
    "\n",
    "import mp_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_factor = 3\n",
    "num_rf_predictors = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_df = pd.read_csv('data/Ath_TF_list.txt', sep='\\t')\n",
    "tf_list = tf_df['Gene_ID']s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_2_3(iterable):\n",
    "    \"powerset([1,2,3]) -->  (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_df = pd.read_csv('data/SS/92_DEG_Clusters.csv', index_col=0)\n",
    "ranking_path = 'output/GSE97500/'\n",
    "deg_genes = deg_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deg genes for presentation only:\n",
    "all_common_tf_set = set(tf_list)\n",
    "deg_genes = ['AT1G77760', 'AT3G44300', 'AT1G69870', 'AT2G46680', 'AT2G46820', 'AT1G14040']\n",
    "deg_genes_top_influencer_lists = []\n",
    "data_sources = ['data/GSE97500/', 'data/GSE111062_RAW/', 'data/GSE158898/']\n",
    "ranking_sources = ['output/GSE97500/', 'output/GSE111062/', 'output/GSE158898/']\n",
    "for gene in deg_genes:\n",
    "    top_set = set()\n",
    "    for source in ranking_sources:\n",
    "        df = pd.read_csv(source+gene+'_rankings.csv', index_col=0, names=['impact']).sort_values(by='impact',ascending=False)\n",
    "        top_set = top_set.union(set(df.head(100).index))\n",
    "        all_common_tf_set = all_common_tf_set.intersection(df.index)\n",
    "    deg_genes_top_influencer_lists.append(list(top_set.intersection(all_common_tf_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('data/GSE97500/expression.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.read_csv(f, sep='\\t', index_col=0) for f in ['data/GSE111062_RAW/expression.tsv', 'data/GSE158898/expression.tsv']]\n",
    "\n",
    "common_index = pd.Series(list(set(dfs[0].index).intersection(set(dfs[1].index))))\n",
    "# dfs = [df.div(df.sum(axis=1), axis=0, fill_value=0.00001) for df in dfs]\n",
    "\n",
    "dfs[0].iloc[:,:] = Normalizer(norm='l1').fit_transform(dfs[0])\n",
    "dfs[1].iloc[:,:] = Normalizer(norm='l1').fit_transform(dfs[1])\n",
    "# Combine the list of dataframes\n",
    "ss_df = pd.concat([dfs[0].loc[common_index], dfs[1].loc[common_index]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_genes = pd.Series(list(set(deg_genes).intersection(set(ts_df.index))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('data/GSE97500/meta_data.tsv', sep='\\t')\n",
    "ts_exp_index = meta_df[meta_df['isTs']]\n",
    "ts_exp_index_target =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].condName\n",
    "ts_exp_index_source =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].prevCol\n",
    "# ts_exp_index_target =  ts_exp_index.condName\n",
    "# ts_exp_index_source =  ts_exp_index.condName\n",
    "regulator_gene_index = ts_df.index\n",
    "regulator_gene_index = pd.Series(list(set(tf_list).intersection(set(regulator_gene_index))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2699004/2699004 [02:22<00:00, 18963.45it/s]\n",
      "100%|██████████| 2699004/2699004 [02:24<00:00, 18615.05it/s]\n",
      "100%|██████████| 1456935/1456935 [01:17<00:00, 18807.52it/s]\n",
      "100%|██████████| 1456935/1456935 [01:19<00:00, 18440.06it/s]\n",
      "100%|██████████| 2635500/2635500 [02:23<00:00, 18369.02it/s]\n",
      "100%|██████████| 2635500/2635500 [02:24<00:00, 18181.18it/s]\n",
      "100%|██████████| 3898895/3898895 [03:36<00:00, 18036.06it/s]\n",
      "100%|██████████| 3898895/3898895 [03:35<00:00, 18067.43it/s]\n",
      "100%|██████████| 4499950/4499950 [04:05<00:00, 18353.42it/s]\n",
      "100%|██████████| 4499950/4499950 [04:08<00:00, 18122.66it/s]\n",
      "100%|██████████| 3697960/3697960 [03:17<00:00, 18713.39it/s]\n",
      "100%|██████████| 3697960/3697960 [03:22<00:00, 18283.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ts_train_y_list = ts_df[ts_exp_index_target]\n",
    "\n",
    "result_list = []\n",
    "result_measure_list = []\n",
    "\n",
    "for target_gene, top_influence_genes in zip(target_genes, deg_genes_top_influencer_lists):\n",
    "\n",
    "    ts_train_y = ts_train_y_list.loc[target_gene]\n",
    "\n",
    "    ts_train_X = ts_df[ts_exp_index_source].T[top_influence_genes]\n",
    "\n",
    "    ss_train_y = ss_df.loc[target_gene]\n",
    "    ss_train_X = ss_df.T[top_influence_genes]\n",
    "    \n",
    "    # importance_df = pd.read_csv(ranking_path+target_gene+'_rankings.csv',index_col=0, names=['impact']).sort_values('impact')\n",
    "    # mean_importance = importance_df.impact.values\n",
    "    # importance_df_list.append(mean_importance)\n",
    "    data_mean = ts_df.T[top_influence_genes].mean()\n",
    "    data_std = ts_df.T[top_influence_genes].std()\n",
    "    regr_ts = RandomForestRegressor(random_state=42, warm_start=True, n_estimators=300, n_jobs=20)\n",
    "    regr_ts = regr_ts.fit(ts_train_X, ts_train_y)\n",
    "\n",
    "\n",
    "    base_prediction = regr_ts.predict(np.array(data_mean).reshape(1,-1))[0]\n",
    "    y_std = ts_df.T.std()[target_gene]\n",
    "\n",
    "    perturbation_input_mat = []\n",
    "    for regulator in top_influence_genes:\n",
    "        perturbation_input = data_mean.copy()\n",
    "        perturbation_input[regulator] += data_std[regulator] * perturbation_factor\n",
    "        perturbation_input_mat.append(perturbation_input.values)\n",
    "    single_result_measure_list = (regr_ts.predict(perturbation_input_mat) - base_prediction)/y_std\n",
    "\n",
    "    perturbation_result_list = []\n",
    "    perturbation_list = list(choose_2_3(top_influence_genes))\n",
    "    perturbation_single_impact_list = list(choose_2_3(single_result_measure_list))\n",
    "    perturbation_list_names = ['; '.join(perturbation_genes) for perturbation_genes in perturbation_list]\n",
    "    perturbation_input_mat = []\n",
    "    single_max_impact = []\n",
    "    for single_impacts in perturbation_single_impact_list:\n",
    "        single_max_impact.append(np.max(single_impacts))\n",
    "\n",
    "    for perturbation_genes in tqdm(perturbation_list):\n",
    "        perturbation_input = data_mean.copy()\n",
    "        for gene in perturbation_genes:\n",
    "            perturbation_input[gene] += data_std[gene] * perturbation_factor\n",
    "        perturbation_input_mat.append(perturbation_input.values)\n",
    "    perturbation_input_mat = np.array(perturbation_input_mat)\n",
    "    result_measure_list = (regr_ts.predict(perturbation_input_mat) - base_prediction)/y_std\n",
    "    out_df = pd.DataFrame(index=perturbation_list_names, data=result_measure_list, columns=['ts_impact'])\n",
    "    out_df['ts_impact_premium'] = np.subtract(result_measure_list, np.array(single_max_impact))\n",
    "\n",
    "    # steady state data part\n",
    "    data_mean = ss_df.T[top_influence_genes].mean()\n",
    "    data_std = ss_df.T[top_influence_genes].std()\n",
    "    regr_ss = RandomForestRegressor(random_state=42, warm_start=True, n_estimators=300, n_jobs=20)\n",
    "    regr_ss = regr_ss.fit(ss_train_X, ss_train_y)\n",
    "\n",
    "\n",
    "    base_prediction = regr_ss.predict(np.array(data_mean).reshape(1,-1))[0]\n",
    "    y_std = ss_df.T.std()[target_gene]\n",
    "\n",
    "    perturbation_input_mat = []\n",
    "    for regulator in top_influence_genes:\n",
    "        perturbation_input = data_mean.copy()\n",
    "        perturbation_input[regulator] += data_std[regulator] * perturbation_factor\n",
    "        perturbation_input_mat.append(perturbation_input.values)\n",
    "    single_result_measure_list = (regr_ss.predict(perturbation_input_mat) - base_prediction)/y_std\n",
    "\n",
    "    perturbation_result_list = []\n",
    "    # perturbation_list = list(choose_2_3(top_influence_genes))\n",
    "    # perturbation_single_impact_list = list(choose_2_3(single_result_measure_list))\n",
    "    perturbation_list_names = ['; '.join(perturbation_genes) for perturbation_genes in perturbation_list]\n",
    "    perturbation_input_mat = []\n",
    "    single_max_impact = []\n",
    "    for single_impacts in perturbation_single_impact_list:\n",
    "        single_max_impact.append(np.max(single_impacts))\n",
    "\n",
    "    for perturbation_genes in tqdm(perturbation_list):\n",
    "        perturbation_input = data_mean.copy()\n",
    "        for gene in perturbation_genes:\n",
    "            perturbation_input[gene] += data_std[gene] * perturbation_factor\n",
    "        perturbation_input_mat.append(perturbation_input.values)\n",
    "    perturbation_input_mat = np.array(perturbation_input_mat)\n",
    "    result_measure_list = (regr_ss.predict(perturbation_input_mat) - base_prediction)/y_std\n",
    "    out_df['ss_impact'] = result_measure_list\n",
    "    out_df['ss_impact_premium'] = np.subtract(result_measure_list, np.array(single_max_impact))\n",
    "\n",
    "    out_df = out_df[(out_df['ts_impact_premium'] >= 0) & (out_df['ss_impact_premium'] >= 0)]\n",
    "    out_df['average_premium'] = (out_df.ts_impact_premium + out_df.ss_impact_premium)/2\n",
    "    out_df['average_premium_rank'] = (np.argsort(np.argsort(out_df.ts_impact_premium)) + np.argsort(np.argsort(out_df.ss_impact_premium)))/2\n",
    "    out_df.sort_values('average_premium_rank', ascending=False).to_csv('output/'+target_gene+'_synergy_ranking.csv')\n",
    "\n",
    "    # out_df.sort_values(by='impact', ascending=False).to_csv(ranking_path+'induction_'+target_gene+'_rankings.csv')\n",
    "\n",
    "    # repression part\n",
    "    # top_influence_genes = train_gene_index[np.argsort(mean_importance)[:100]]\n",
    "    # importance_df_list.append(mean_importance)\n",
    "    # data_mean = ts_df.T[top_influence_genes].mean()\n",
    "    # data_std = ts_df.T[top_influence_genes].std()\n",
    "    # regr = RandomForestRegressor(random_state=42, warm_start=True, n_estimators=300, n_jobs=20)\n",
    "    # ts_train_X = ts_df[ts_exp_index_source].T[top_influence_genes]\n",
    "    # regr = regr.fit(ts_train_X, ts_train_y)\n",
    "\n",
    "    # base_prediction = regr.predict(np.array(data_mean).reshape(1,-1))[0]\n",
    "    # y_std = ts_df.T.std()[target_gene]\n",
    "    # perturbation_list = list(choose_2_3(top_influence_genes))\n",
    "\n",
    "    # perturbation_result_list = []\n",
    "    # perturbation_list_names = ['; '.join(perturbation_genes) for perturbation_genes in perturbation_list]\n",
    "    # perturbation_input_mat = []\n",
    "    # for perturbation_genes in perturbation_list:\n",
    "    #     perturbation_input = data_mean.copy()\n",
    "    #     for gene in perturbation_genes:\n",
    "    #         perturbation_input[gene] += data_std[gene] * perturbation_factor\n",
    "    #     perturbation_input_mat.append(perturbation_input.values)\n",
    "    # perturbation_input_mat = np.array(perturbation_input_mat)\n",
    "    # result_measure_list = (regr.predict(perturbation_input_mat) - base_prediction)/y_std\n",
    "    # out_df = pd.DataFrame(index=perturbation_list_names, data=result_measure_list, columns=['impact'])\n",
    "    # out_df.sort_values(by='impact').to_csv(ranking_path+'repression_'+target_gene+'_rankings.csv')\n",
    "\n",
    "    #     perturbation_prediction = regr.predict(np.array(perturbation_input).reshape(1,-1))[0]\n",
    "    #     perturbation_measure = (perturbation_prediction - base_prediction)/y_std\n",
    "    #     perturbation_result_list.append(perturbation_measure)\n",
    "    # result_list.append(np.array(perturbation_list_names)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "    # result_measure_list.append(np.array(perturbation_result_list)[np.argsort(perturbation_result_list)[::-1][:5]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_df[(out_df['ts_impact_premium'] >= 0) & (out_df['ss_impact_premium'] >= 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['average_premium'] = (out_df.ts_impact_premium + out_df.ss_impact_premium)/2\n",
    "out_df['average_premium_rank'] = (np.argsort(np.argsort(out_df.ts_impact_premium)) + np.argsort(np.argsort(out_df.ss_impact_premium)))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.sort_values('average_premium_rank', ascending=False).to_csv('output/'+target_gene+'_synergy_ranking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 5, 4, 0, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([3,6,1,2,8,5])\n",
    "np.argsort(np.argsort(test)[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 0, 5, 1, 4])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_impact</th>\n",
       "      <th>ts_impact_premium</th>\n",
       "      <th>ss_impact</th>\n",
       "      <th>ss_impact_premium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT5G05790; AT3G15210</th>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5G05790; AT1G19000</th>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5G05790; AT1G80840</th>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5G05790; AT4G25470</th>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5G05790; AT5G52510</th>\n",
       "      <td>-0.005641</td>\n",
       "      <td>-0.006993</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.191044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT4G36780; AT5G60690; AT4G37260</th>\n",
       "      <td>0.006601</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.186520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40140; AT4G21750; AT5G60690</th>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.186872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40140; AT4G21750; AT4G37260</th>\n",
       "      <td>-0.002287</td>\n",
       "      <td>-0.002295</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.192388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40140; AT5G60690; AT4G37260</th>\n",
       "      <td>0.003229</td>\n",
       "      <td>-0.002295</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.186872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT4G21750; AT5G60690; AT4G37260</th>\n",
       "      <td>0.003238</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>62167.192396</td>\n",
       "      <td>62167.186872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2699004 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ts_impact  ts_impact_premium     ss_impact  \\\n",
       "AT5G05790; AT3G15210              0.001590           0.000239  62167.192396   \n",
       "AT5G05790; AT1G19000              0.001352           0.000000  62167.192396   \n",
       "AT5G05790; AT1G80840              0.001400           0.000049  62167.192396   \n",
       "AT5G05790; AT4G25470              0.002521           0.001170  62167.192396   \n",
       "AT5G05790; AT5G52510             -0.005641          -0.006993  62167.192396   \n",
       "...                                    ...                ...           ...   \n",
       "AT4G36780; AT5G60690; AT4G37260   0.006601           0.000724  62167.192396   \n",
       "AT2G40140; AT4G21750; AT5G60690   0.005532           0.000008  62167.192396   \n",
       "AT2G40140; AT4G21750; AT4G37260  -0.002287          -0.002295  62167.192396   \n",
       "AT2G40140; AT5G60690; AT4G37260   0.003229          -0.002295  62167.192396   \n",
       "AT4G21750; AT5G60690; AT4G37260   0.003238          -0.002287  62167.192396   \n",
       "\n",
       "                                 ss_impact_premium  \n",
       "AT5G05790; AT3G15210                  62167.191044  \n",
       "AT5G05790; AT1G19000                  62167.191044  \n",
       "AT5G05790; AT1G80840                  62167.191044  \n",
       "AT5G05790; AT4G25470                  62167.191044  \n",
       "AT5G05790; AT5G52510                  62167.191044  \n",
       "...                                            ...  \n",
       "AT4G36780; AT5G60690; AT4G37260       62167.186520  \n",
       "AT2G40140; AT4G21750; AT5G60690       62167.186872  \n",
       "AT2G40140; AT4G21750; AT4G37260       62167.192388  \n",
       "AT2G40140; AT5G60690; AT4G37260       62167.186872  \n",
       "AT4G21750; AT5G60690; AT4G37260       62167.186872  \n",
       "\n",
       "[2699004 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1757861"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.subtract(result_measure_list, np.array(single_max_impact))\n",
    "test.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1003040165929691"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_measure_list[1757861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1003040165929691"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(result_measure_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035439268642510874"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_max_impact[1757861]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0548930272772657"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(single_max_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013516861626811376\n"
     ]
    }
   ],
   "source": [
    "for i in choose_2_3(single_perturbation_df.impact.values):\n",
    "    print(np.max(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('AT5G05790', 'AT3G15210')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perturbation_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "impact    0.001352\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_perturbation_df.loc[list(perturbation_genes)].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_input_mat = np.array(perturbation_input_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure_list = (regr.predict(perturbation_input_mat) - base_prediction)/y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_df = pd.DataFrame(index=perturbation_list_names, data=result_measure_list, columns=['impact'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT2G23340; AT1G72740; AT2G32250</th>\n",
       "      <td>0.986700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT5G45710; AT2G23340; AT2G32250</th>\n",
       "      <td>0.985742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G23340; AT2G32250; AT3G06410</th>\n",
       "      <td>0.982229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G23340; AT4G24240; AT2G32250</th>\n",
       "      <td>0.975762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G23340; AT3G09600; AT2G32250</th>\n",
       "      <td>0.964266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40750; AT5G67450; AT4G25400</th>\n",
       "      <td>-0.035687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40750; AT4G25400; AT1G76890</th>\n",
       "      <td>-0.036086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40750; AT4G24540; AT4G01500</th>\n",
       "      <td>-0.038401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40750; AT4G01500; AT4G25400</th>\n",
       "      <td>-0.038960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AT2G40750; AT4G24540; AT4G25400</th>\n",
       "      <td>-0.042633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166750 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   impact\n",
       "AT2G23340; AT1G72740; AT2G32250  0.986700\n",
       "AT5G45710; AT2G23340; AT2G32250  0.985742\n",
       "AT2G23340; AT2G32250; AT3G06410  0.982229\n",
       "AT2G23340; AT4G24240; AT2G32250  0.975762\n",
       "AT2G23340; AT3G09600; AT2G32250  0.964266\n",
       "...                                   ...\n",
       "AT2G40750; AT5G67450; AT4G25400 -0.035687\n",
       "AT2G40750; AT4G25400; AT1G76890 -0.036086\n",
       "AT2G40750; AT4G24540; AT4G01500 -0.038401\n",
       "AT2G40750; AT4G01500; AT4G25400 -0.038960\n",
       "AT2G40750; AT4G24540; AT4G25400 -0.042633\n",
       "\n",
       "[166750 rows x 1 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.sort_values(by='impact', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_measure_list = np.array(result_measure_list)\n",
    "result_list = np.array(result_list)\n",
    "out_df = pd.DataFrame()\n",
    "out_df.index = target_genes\n",
    "for i in range(5):\n",
    "    comb_name = 'top_{}_combination'.format(i+1)\n",
    "    score_name = 'top_{}_score'.format(i+1)\n",
    "    out_df[comb_name] = result_list[:,i]\n",
    "    out_df[score_name] = result_measure_list[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv('output/GSE111062/presentation_comb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for importance_series, target_gene in zip(importance_df_list, target_genes):\n",
    "    importance_series.to_csv('output/GSE111062/'+target_gene+'_rankings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G49690')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G26744')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G23250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df_list[5].sort_values().index.get_loc('AT3G26744')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('inf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45e8b4e597901076a3793f077aa4917c88e4588bf4d8f42473ef14bed5440d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
