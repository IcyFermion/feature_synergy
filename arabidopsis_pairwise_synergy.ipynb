{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from multiprocessing import shared_memory\n",
    "from multiprocessing.dummy import Pool\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import multiprocessing as mp\n",
    "from itertools import chain, combinations\n",
    "import sys\n",
    "import os\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import mp_run\n",
    "\n",
    "import concurrent.futures\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\" # export OMP_NUM_THREADS=1\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\" # export OPENBLAS_NUM_THREADS=1\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" # export MKL_NUM_THREADS=1\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\" # export VECLIB_MAXIMUM_THREADS=1\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" # export NUMEXPR_NUM_THREADS=1\n",
    "\n",
    "# styling:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use(['ggplot'])\n",
    "sns.set_palette(\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation_factor = 3\n",
    "num_rf_predictors = 500\n",
    "\n",
    "num_deg_targets = 2000\n",
    "target_tf = 'AT2G46680'\n",
    "\n",
    "induction_flag = 1\n",
    "mp_threads = 20\n",
    "# if (len(sys.argv)>=3):\n",
    "#     induction_flag = bool(sys.argv[1])\n",
    "#     mp_threads = int(sys.argv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_2_3(iterable):\n",
    "    \"powerset([1,2,3]) -->  (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(2,4))\n",
    "\n",
    "def choose_2(iterable):\n",
    "    \"powerset([1,2,3]) -->  (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv('data/GSE97500/expression.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# filter out chloroplast and mitochondrial genes\n",
    "ts_df = ts_df[:28433]\n",
    "\n",
    "meta_df = pd.read_csv('data/GSE97500/meta_data.tsv', sep='\\t')\n",
    "ts_exp_index = meta_df[meta_df['isTs']]\n",
    "ts_exp_index_target =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].condName\n",
    "ts_exp_index_source =  ts_exp_index[ts_exp_index['is1stLast'] != 'f'].prevCol\n",
    "\n",
    "kirk_res = pd.read_csv('./data/dt_for_Bingran.tsv', sep='\\t')\n",
    "kirk_tf_set = set([name.split('_')[0] for name in kirk_res['V2'].values])\n",
    "# add HB7 and CRF4 to the list of TFs to be tested\n",
    "test_tf_set = kirk_tf_set.union(set(['AT2G46680', 'AT4G27950']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_exp_df = ts_df.drop(labels=test_tf_set)\n",
    "tf_exp_df = ts_df.loc[test_tf_set]\n",
    "\n",
    "deg_targets = target_exp_df.std(axis=1).sort_values(ascending=False)[:num_deg_targets].index\n",
    "target_df = target_exp_df.loc[deg_targets][ts_exp_index_target]\n",
    "tf_df = tf_exp_df[ts_exp_index_source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_list = list(test_tf_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_names = []\n",
    "combo_length = 0\n",
    "for i, j in combinations(range(len(tf_list)),2):\n",
    "    combo_names.append(tf_list[i] + '_' + tf_list[j])\n",
    "    combo_length += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(index=combo_names)\n",
    "res_mat = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for target_gene in tqdm(deg_targets)\n",
    "    \n",
    "    ts_train_X = tf_df.T\n",
    "\n",
    "    ts_train_y = target_df.loc[target_gene]\n",
    "\n",
    "    input_mean = ts_train_X.mean()\n",
    "    input_std = ts_train_X.std()\n",
    "\n",
    "    # \n",
    "\n",
    "    combos = choose_2(range(len(tf_list)))\n",
    "\n",
    "    perturbation_input_single = input_mean.copy()\n",
    "    perturbation_input_double = input_mean.copy()\n",
    "    perturbation_input_single = np.tile(perturbation_input_single.values, (len(tf_list),1))\n",
    "    perturbation_input_double = np.tile(perturbation_input_double.values, (combo_length,1))\n",
    "\n",
    "    for i, tf_name in enumerate(tf_list):\n",
    "        perturbation_input_single[i][i] += input_std[tf_name]*perturbation_factor\n",
    "    for k, (i,j) in enumerate(combinations(range(len(tf_list)),2)):\n",
    "        perturbation_input_double[k][i] += input_std[tf_list[i]]*perturbation_factor\n",
    "        perturbation_input_double[k][j] += input_std[tf_list[j]]*perturbation_factor\n",
    "\n",
    "    func = partial(mp_run.regr_perturbation, ts_train_X, ts_train_y, perturbation_input_single, perturbation_input_double)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(func, range(num_rf_predictors))\n",
    "\n",
    "    single_results = []\n",
    "    double_results = []\n",
    "    for result in results:\n",
    "        single_results.append(result[0])\n",
    "        double_results.append(result[1])\n",
    "    single_results = np.array(single_results)\n",
    "    double_results = np.array(double_results)\n",
    "\n",
    "    p_val_list = []\n",
    "    for k, (i,j) in enumerate(combinations(range(len(tf_list)),2)):\n",
    "        double_effects = double_results[:,k]\n",
    "        single_effect_a = single_results[:,i]\n",
    "        single_effect_b = single_results[:,j]\n",
    "        t_val, p_val = stats.ttest_rel(np.abs(double_effects), np.abs(single_effect_a) + np.abs(single_effect_b))\n",
    "        if (t_val < 0) or (single_effect_a.mean()*single_effect_b.mean() < 0):\n",
    "            p_val = 1\n",
    "        p_val_list.append(p_val)\n",
    "    p_val_list = np.array(p_val_list)\n",
    "    res_mat.append(p_val_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pymc_env]",
   "language": "python",
   "name": "conda-env-pymc_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
