{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripts for regression experiments on mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "import re\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "# regex for number extraction from string\n",
    "number_pattern =  r'(-?(?:0|[1-9]\\d*)(?:\\.\\d+)?(?:[eE][+-]?\\d+)?)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts training/testing data curation \n",
    "\n",
    "df_1 = pd.read_csv('./GSE145936/GSE145936_Sis1-AA_Gene_counts_normalized.txt.gz', sep='\\t', index_col=0, compression='gzip')\n",
    "df_2 = pd.read_csv('./GSE153609/GSE153609_gene_expression_TPM_all_times.csv.gz', index_col=0, compression='gzip')\n",
    "df_3 = pd.read_csv('./GSE168699/GSE168699_RNA_TPM_all_times.csv.gz', index_col=0, compression='gzip')\n",
    "df_4_1 = pd.read_csv('./GSE226769/GSE226769_Meiotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_4_2 = pd.read_csv('./GSE226769/GSE226769_Mitotic_Depletion_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_4_3 = pd.read_csv('./GSE226769/GSE226769_UME6_T99N_AltAD_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "df_4_4 = pd.read_csv('./GSE226769/GSE226769_UME6_T99N_Rescue_TPMs.csv.gz', compression='gzip', index_col=0)\n",
    "\n",
    "to_drop = df_3.columns[:7]\n",
    "df_3 = df_3.drop(labels=to_drop, axis=1)\n",
    "df_1 = df_1.drop(labels=['gene name'], axis=1)\n",
    "\n",
    "common_genes = set(df_1.index).intersection(set(df_2.index)).intersection(set(df_3.index))\n",
    "common_genes = list(common_genes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_source_target_split(df, time_set, rep_set):\n",
    "    sorted_time_list = sorted(time_set, key=lambda time_str: float(re.search(number_pattern, time_str).group(1)))\n",
    "    print(sorted_time_list)\n",
    "\n",
    "    train_source_time = sorted_time_list[:-2]\n",
    "    train_target_time = sorted_time_list[1:-1]\n",
    "    test_source_time = sorted_time_list[-2:-1]\n",
    "    test_target_time = sorted_time_list[-1:]\n",
    "\n",
    "    train_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_source_time)]\n",
    "    train_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), train_target_time)]\n",
    "    test_source_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_source_time)]\n",
    "    test_target_list = ['@'.join([x, y]) for x, y in product(list(rep_set), test_target_time)]\n",
    "    return df[train_source_list], df[train_target_list], df[test_source_list], df[test_target_list]\n",
    "\n",
    "def format_index_and_normalize(df):\n",
    "    normalized_df = df.apply(stats.zscore, axis=0)\n",
    "    selected_index_list = []\n",
    "    new_index_list = []\n",
    "    for index_name in df.index:\n",
    "        names = index_name.split('Name=')[-1]\n",
    "        if ('/' in names):\n",
    "            name_list = names.split('/')[:2]\n",
    "            for name in name_list:\n",
    "                if (name in common_genes):\n",
    "                    selected_index_list.append(index_name)\n",
    "                    new_index_list.append(name)\n",
    "                    continue\n",
    "        elif (names in common_genes):\n",
    "            selected_index_list.append(index_name)\n",
    "            new_index_list.append(names)\n",
    "            continue\n",
    "    len(new_index_list)\n",
    "    new_df = normalized_df.loc[selected_index_list]\n",
    "    new_df.index = new_index_list\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4_1 = format_index_and_normalize(df_4_1)\n",
    "df_4_2 = df_4_2.drop(columns=df_4_2.columns[-6:])\n",
    "df_4_2 = format_index_and_normalize(df_4_2)\n",
    "df_4_3 = format_index_and_normalize(df_4_3)\n",
    "df_4_4 = format_index_and_normalize(df_4_4)\n",
    "\n",
    "common_genes = set(common_genes).intersection(set(df_4_1.index), set(df_4_2.index), set(df_4_3.index), set(df_4_4.index))\n",
    "common_genes = list(common_genes)\n",
    "\n",
    "df_4_1 = df_4_1.loc[common_genes]\n",
    "df_4_2 = df_4_2.loc[common_genes]\n",
    "df_4_3 = df_4_3.loc[common_genes]\n",
    "df_4_4 = df_4_4.loc[common_genes]\n",
    "df_4_1 = df_4_1[~df_4_1.index.duplicated(keep='first')]\n",
    "df_4_2 = df_4_2[~df_4_2.index.duplicated(keep='first')]\n",
    "df_4_3 = df_4_3[~df_4_3.index.duplicated(keep='first')]\n",
    "df_4_4 = df_4_4[~df_4_4.index.duplicated(keep='first')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n",
      "['0.5HR', '2HR', '2.5HR', '3HR', '4.5HR', '6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_4_1.columns:\n",
    "    name_segments = name.split('_')\n",
    "    rep_name = ''.join(name_segments[:-1])\n",
    "    time_name = name_segments[-1]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "print(len(rep_set), len(time_set))\n",
    "df_4_1.columns = formated_name_list\n",
    "normalized_df = df_4_1.apply(stats.zscore, axis=0)\n",
    "df_split_1 = train_test_source_target_split(normalized_df, time_set, rep_set)\n",
    "\n",
    "df_split_1[0].to_csv('./GSE226769/normalized/train_source_1.csv.gz', compression='gzip')\n",
    "df_split_1[1].to_csv('./GSE226769/normalized/train_target_1.csv.gz', compression='gzip')\n",
    "df_split_1[2].to_csv('./GSE226769/normalized/test_source_1.csv.gz', compression='gzip')\n",
    "df_split_1[3].to_csv('./GSE226769/normalized/test_target_1.csv.gz', compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-30min', '0min', '15min', '30min', '60min', '120min']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_4_2.columns:\n",
    "    pattern = r'(.*)\\(([^()]*)\\)(.*)' \n",
    "    match = re.match(pattern, name)\n",
    "    rep_name = match.group(1) + match.group(3)\n",
    "    rep_set.add(rep_name)\n",
    "    time_name = match.group(2)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)\n",
    "df_4_2.columns = formated_name_list\n",
    "normalized_df = df_4_2.apply(stats.zscore, axis=0)\n",
    "df_split_2 = train_test_source_target_split(normalized_df, time_set, rep_set)\n",
    "\n",
    "df_split_2[0].to_csv('./GSE226769/normalized/train_source_2.csv.gz', compression='gzip')\n",
    "df_split_2[1].to_csv('./GSE226769/normalized/train_target_2.csv.gz', compression='gzip')\n",
    "df_split_2[2].to_csv('./GSE226769/normalized/test_source_2.csv.gz', compression='gzip')\n",
    "df_split_2[3].to_csv('./GSE226769/normalized/test_target_2.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 4\n",
      "['0HR', '2HR', '4HR', '6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_4_3.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_4_3.columns = formated_name_list\n",
    "normalized_df = df_4_3.apply(stats.zscore, axis=0)\n",
    "df_split_3 = train_test_source_target_split(normalized_df, time_set, rep_set)\n",
    "\n",
    "df_split_3[0].to_csv('./GSE226769/normalized/train_source_3.csv.gz', compression='gzip')\n",
    "df_split_3[1].to_csv('./GSE226769/normalized/train_target_3.csv.gz', compression='gzip')\n",
    "df_split_3[2].to_csv('./GSE226769/normalized/test_source_3.csv.gz', compression='gzip')\n",
    "df_split_3[3].to_csv('./GSE226769/normalized/test_target_3.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 4\n",
      "[' 0HR', ' 2HR', ' 4HR', ' 6HR']\n"
     ]
    }
   ],
   "source": [
    "rep_set = set()\n",
    "time_set = set()\n",
    "formated_name_list = []\n",
    "for name in df_4_4.columns:\n",
    "    name_segments = name.split('_')\n",
    "    if (len(name_segments) == 2):\n",
    "        rep_name = name_segments[0]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 3):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[2]\n",
    "        time_name = name_segments[1]\n",
    "    elif (len(name_segments) == 4):\n",
    "        rep_name = name_segments[0] + '~' + name_segments[1] + '~' + name_segments[3]\n",
    "        time_name = name_segments[2]\n",
    "    rep_set.add(rep_name)\n",
    "    time_set.add(time_name)\n",
    "    formated_name_list.append(rep_name+'@'+time_name)   \n",
    "print(len(rep_set), len(time_set))\n",
    "df_4_4.columns = formated_name_list\n",
    "normalized_df = df_4_4.apply(stats.zscore, axis=0)\n",
    "df_split_4 = train_test_source_target_split(normalized_df, time_set, rep_set)\n",
    "\n",
    "df_split_4[0].to_csv('./GSE226769/normalized/train_source_4.csv.gz', compression='gzip')\n",
    "df_split_4[1].to_csv('./GSE226769/normalized/train_target_4.csv.gz', compression='gzip')\n",
    "df_split_4[2].to_csv('./GSE226769/normalized/test_source_4.csv.gz', compression='gzip')\n",
    "df_split_4[3].to_csv('./GSE226769/normalized/test_target_4.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df_1=df_1.apply(stats.zscore, axis=0)\n",
    "normalized_df_2=df_2.apply(stats.zscore, axis=0)\n",
    "normalized_df_3=df_3.apply(stats.zscore, axis=0)\n",
    "\n",
    "normalized_df_1 = normalized_df_1.loc[common_genes]\n",
    "normalized_df_2 = normalized_df_2.loc[common_genes]\n",
    "normalized_df_3 = normalized_df_3.loc[common_genes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_df_1 = normalized_df_1.iloc[:, [0,1,2,6,7,8]]\n",
    "train_target_df_1 = normalized_df_1.iloc[:, [1,2,3,7,8,9]]\n",
    "test_source_df_1 = normalized_df_1.iloc[:, [3,4,9,10]]\n",
    "test_target_df_1 = normalized_df_1.iloc[:, [4,5,10,11]]\n",
    "\n",
    "train_source_df_2 = normalized_df_2.iloc[:, [0,1,2]]\n",
    "train_target_df_2 = normalized_df_2.iloc[:, [1,2,3]]\n",
    "test_source_df_2 = normalized_df_2.iloc[:, [3,4]]\n",
    "test_target_df_2 = normalized_df_2.iloc[:, [4,5]]\n",
    "\n",
    "train_source_df_3 = normalized_df_3.iloc[:, :-6]\n",
    "train_target_df_3 = normalized_df_3.iloc[:, 1:-5]\n",
    "test_source_df_3 = normalized_df_3.iloc[:, -6:-1]\n",
    "test_target_df_3 = normalized_df_3.iloc[:, -5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_df_1.to_csv('./GSE145936/normalized/train_source.csv.gz', compression='gzip')\n",
    "train_target_df_1.to_csv('./GSE145936/normalized/train_target.csv.gz', compression='gzip')\n",
    "test_source_df_1.to_csv('./GSE145936/normalized/test_source.csv.gz', compression='gzip')\n",
    "test_target_df_1.to_csv('./GSE145936/normalized/test_target.csv.gz', compression='gzip')\n",
    "\n",
    "train_source_df_2.to_csv('./GSE153609/normalized/train_source.csv.gz', compression='gzip')\n",
    "train_target_df_2.to_csv('./GSE153609/normalized/train_target.csv.gz', compression='gzip')\n",
    "test_source_df_2.to_csv('./GSE153609/normalized/test_source.csv.gz', compression='gzip')\n",
    "test_target_df_2.to_csv('./GSE153609/normalized/test_target.csv.gz', compression='gzip')\n",
    "\n",
    "train_source_df_3.to_csv('./GSE168699/normalized/train_source.csv.gz', compression='gzip')\n",
    "train_target_df_3.to_csv('./GSE168699/normalized/train_target.csv.gz', compression='gzip')\n",
    "test_source_df_3.to_csv('./GSE168699/normalized/test_source.csv.gz', compression='gzip')\n",
    "test_target_df_3.to_csv('./GSE168699/normalized/test_target.csv.gz', compression='gzip')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
